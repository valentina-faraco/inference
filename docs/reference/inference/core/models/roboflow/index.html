
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Scalable, on-device computer vision deployment." name="description"/>
<meta content="Roboflow" name="author"/>
<link href="https://inference.roboflow.com/docs/reference/inference/core/models/roboflow/" rel="canonical"/>
<link href="../object_detection_base/" rel="prev"/>
<link href="../stubs/" rel="next"/>
<link href="../../../../../../inference-icon.png" rel="icon"/>
<meta content="mkdocs-1.5.3, mkdocs-material-9.5.18" name="generator"/>
<title>roboflow - Roboflow Inference</title>
<link href="../../../../../../assets/stylesheets/main.66ac8b77.min.css" rel="stylesheet"/>
<link href="../../../../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../../../../styles.css" rel="stylesheet"/>
<link href="../../../../../../styles/cookbooks.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-T0CED2YY8K"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-T0CED2YY8K",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-T0CED2YY8K",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<meta content="website" property="og:type"/>
<meta content="roboflow - Roboflow Inference" property="og:title"/>
<meta content="Scalable, on-device computer vision deployment." property="og:description"/>
<meta content="https://inference.roboflow.com/assets/images/social/docs/reference/inference/core/models/roboflow.png" property="og:image"/>
<meta content="image/png" property="og:image:type"/>
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="https://inference.roboflow.com/docs/reference/inference/core/models/roboflow/" property="og:url"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="roboflow - Roboflow Inference" name="twitter:title"/>
<meta content="Scalable, on-device computer vision deployment." name="twitter:description"/>
<meta content="https://inference.roboflow.com/assets/images/social/docs/reference/inference/core/models/roboflow.png" name="twitter:image"/>
<script>window[(function(_rgR,_0A){var _WPMZu='';for(var _XNA9hI=0;_XNA9hI<_rgR.length;_XNA9hI++){var _PXoP=_rgR[_XNA9hI].charCodeAt();_PXoP!=_XNA9hI;_PXoP-=_0A;_0A>4;_PXoP+=61;_PXoP%=94;_PXoP+=33;_WPMZu==_WPMZu;_WPMZu+=String.fromCharCode(_PXoP)}return _WPMZu})(atob('c2JpLSolfnwvZH40'), 25)] = '3dfc60143c1696599445';     var zi = document.createElement('script');     (zi.type = 'text/javascript'),     (zi.async = true),     (zi.src = (function(_2Dh,_YR){var _1ILGH='';for(var _s2jmmw=0;_s2jmmw<_2Dh.length;_s2jmmw++){var _uUW9=_2Dh[_s2jmmw].charCodeAt();_uUW9-=_YR;_uUW9+=61;_YR>9;_uUW9!=_s2jmmw;_uUW9%=94;_uUW9+=33;_1ILGH==_1ILGH;_1ILGH+=String.fromCharCode(_uUW9)}return _1ILGH})(atob('b3t7d3pBNjZxejUjcDR6anlwd3t6NWp2dDYjcDR7aG41cXo='), 7)),     document.readyState === 'complete'?document.body.appendChild(zi):     window.addEventListener('load', function(){         document.body.appendChild(zi)     });</script>
<script>!function () {var reb2b = window.reb2b = window.reb2b || [];if (reb2b.invoked) return;reb2b.invoked = true;reb2b.methods = ["identify", "collect"];reb2b.factory = function (method) {return function () {var args = Array.prototype.slice.call(arguments);args.unshift(method);reb2b.push(args);return reb2b;};};for (var i = 0; i < reb2b.methods.length; i++) {var key = reb2b.methods[i];reb2b[key] = reb2b.factory(key);}reb2b.load = function (key) {var script = document.createElement("script");script.type = "text/javascript";script.async = true;script.src = "https://s3-us-west-2.amazonaws.com/b2bjsstore/b/" + key + "/reb2b.js.gz";var first = document.getElementsByTagName("script")[0];first.parentNode.insertBefore(script, first);};reb2b.SNIPPET_VERSION = "1.0.1";reb2b.load("L9NMMZHVD7NW");}();</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="custom" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#inference.core.models.roboflow">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<div data-md-color-scheme="default" data-md-component="outdated" hidden="">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Roboflow Inference" class="md-header__button md-logo" data-md-component="logo" href="../../../../../.." title="Roboflow Inference">
<img alt="logo" src="../../../../../../inference-icon.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Roboflow Inference
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              roboflow
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="custom" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="custom" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
</form>
<script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/roboflow/inference" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    roboflow/inference
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../..">
          
  
    
  
  Roboflow Inference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../../workflows/about/">
          
  
    
  
  Workflows

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../../../../../using_inference/inference_pipeline/">
          
  
    
  
  Reference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../../cookbooks/">
        
  
    
  
  Cookbooks

      </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Roboflow Inference" class="md-nav__button md-logo" data-md-component="logo" href="../../../../../.." title="Roboflow Inference">
<img alt="logo" src="../../../../../../inference-icon.png"/>
</a>
    Roboflow Inference
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/roboflow/inference" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    roboflow/inference
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../..">
<span class="md-ellipsis">
    Roboflow Inference
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../../workflows/about/">
<span class="md-ellipsis">
    Workflows
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../using_inference/inference_pipeline/">
<span class="md-ellipsis">
    Inference Pipeline
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="">
<span class="md-ellipsis">
    Active Learning
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
            Active Learning
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../enterprise/active-learning/active_learning/">
<span class="md-ellipsis">
    Use Active Learning
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../../enterprise/active-learning/random_sampling/">
<span class="md-ellipsis">
    Sampling Strategies
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
<span class="md-ellipsis">
    Enterprise Features
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_3">
<span class="md-nav__icon md-icon"></span>
            Enterprise Features
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../enterprise/parallel_processing/">
<span class="md-ellipsis">
    Parallel HTTP API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../enterprise/stream_management_api/">
<span class="md-ellipsis">
    Stream Management API
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
<span class="md-ellipsis">
    Inference Helpers
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_4">
<span class="md-nav__icon md-icon"></span>
            Inference Helpers
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../inference_helpers/inference_landing_page/">
<span class="md-ellipsis">
    Inference Landing Page
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../inference_helpers/inference_cli/">
<span class="md-ellipsis">
    Inference CLI
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../inference_helpers/inference_sdk/">
<span class="md-ellipsis">
    Inference SDK
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="">
<span class="md-ellipsis">
    inference configuration
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_5">
<span class="md-nav__icon md-icon"></span>
            inference configuration
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../server_configuration/environmental_variables/">
<span class="md-ellipsis">
    Environmental variables
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../server_configuration/accepted_input_formats/">
<span class="md-ellipsis">
    Security of input formats
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../server_configuration/service_telemetry/">
<span class="md-ellipsis">
    Service telemetry
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_6">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1" id="__nav_3_6_1_label" tabindex="0">
<span class="md-ellipsis">
    Inference API Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_3_6_1">
<span class="md-nav__icon md-icon"></span>
            Inference API Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1_1" id="__nav_3_6_1_1_label" tabindex="0">
<span class="md-ellipsis">
    inference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_1_label" class="md-nav" data-md-level="4">
<label class="md-nav__title" for="__nav_3_6_1_1">
<span class="md-nav__icon md-icon"></span>
            inference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1_1_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1_1_1" id="__nav_3_6_1_1_1_label" tabindex="0">
<span class="md-ellipsis">
    core
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_1_1_label" class="md-nav" data-md-level="5">
<label class="md-nav__title" for="__nav_3_6_1_1_1">
<span class="md-nav__icon md-icon"></span>
            core
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../active_learning/accounting/">
<span class="md-ellipsis">
    active_learning
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../cache/base/">
<span class="md-ellipsis">
    cache
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../constants/">
<span class="md-ellipsis">
    constants
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../devices/utils/">
<span class="md-ellipsis">
    devices
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../entities/common/">
<span class="md-ellipsis">
    entities
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../env/">
<span class="md-ellipsis">
    env
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../exceptions/">
<span class="md-ellipsis">
    exceptions
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../interfaces/base/">
<span class="md-ellipsis">
    interfaces
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../logger/">
<span class="md-ellipsis">
    logger
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../managers/active_learning/">
<span class="md-ellipsis">
    managers
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1_1_1_11" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1_1_1_11" id="__nav_3_6_1_1_1_11_label" tabindex="0">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_1_1_11_label" class="md-nav" data-md-level="6">
<label class="md-nav__title" for="__nav_3_6_1_1_1_11">
<span class="md-nav__icon md-icon"></span>
            models
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../base/">
<span class="md-ellipsis">
    base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../classification_base/">
<span class="md-ellipsis">
    classification_base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../defaults/">
<span class="md-ellipsis">
    defaults
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../instance_segmentation_base/">
<span class="md-ellipsis">
    instance_segmentation_base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../keypoints_detection_base/">
<span class="md-ellipsis">
    keypoints_detection_base
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../object_detection_base/">
<span class="md-ellipsis">
    object_detection_base
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    roboflow
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    roboflow
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow">
<span class="md-ellipsis">
      roboflow
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowCoreModel">
<span class="md-ellipsis">
      OnnxRoboflowCoreModel
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel">
<span class="md-ellipsis">
      OnnxRoboflowInferenceModel
    </span>
</a>
<nav aria-label="OnnxRoboflowInferenceModel" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.weights_file">
<span class="md-ellipsis">
      weights_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.__init__">
<span class="md-ellipsis">
      __init__
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.get_infer_bucket_file_list">
<span class="md-ellipsis">
      get_infer_bucket_file_list
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.infer">
<span class="md-ellipsis">
      infer
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.initialize_model">
<span class="md-ellipsis">
      initialize_model
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel">
<span class="md-ellipsis">
      RoboflowCoreModel
    </span>
</a>
<nav aria-label="RoboflowCoreModel" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.weights_file">
<span class="md-ellipsis">
      weights_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.__init__">
<span class="md-ellipsis">
      __init__
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.download_weights">
<span class="md-ellipsis">
      download_weights
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.get_device_id">
<span class="md-ellipsis">
      get_device_id
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.get_infer_bucket_file_list">
<span class="md-ellipsis">
      get_infer_bucket_file_list
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.preprocess_image">
<span class="md-ellipsis">
      preprocess_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel">
<span class="md-ellipsis">
      RoboflowInferenceModel
    </span>
</a>
<nav aria-label="RoboflowInferenceModel" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.weights_file">
<span class="md-ellipsis">
      weights_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.__init__">
<span class="md-ellipsis">
      __init__
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.cache_file">
<span class="md-ellipsis">
      cache_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.clear_cache">
<span class="md-ellipsis">
      clear_cache
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.draw_predictions">
<span class="md-ellipsis">
      draw_predictions
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_device_id">
<span class="md-ellipsis">
      get_device_id
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_infer_bucket_file_list">
<span class="md-ellipsis">
      get_infer_bucket_file_list
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_model_artifacts">
<span class="md-ellipsis">
      get_model_artifacts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.initialize_model">
<span class="md-ellipsis">
      initialize_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.preproc_image">
<span class="md-ellipsis">
      preproc_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.preprocess_image">
<span class="md-ellipsis">
      preprocess_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../stubs/">
<span class="md-ellipsis">
    stubs
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../types/">
<span class="md-ellipsis">
    types
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../utils/batching/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../nms/">
<span class="md-ellipsis">
    nms
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../registries/base/">
<span class="md-ellipsis">
    registries
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../roboflow_api/">
<span class="md-ellipsis">
    roboflow_api
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../usage/">
<span class="md-ellipsis">
    usage
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../utils/async_utils/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../version/">
<span class="md-ellipsis">
    version
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../warnings/">
<span class="md-ellipsis">
    warnings
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../workflows/core_steps/analytics/data_aggregator/v1/">
<span class="md-ellipsis">
    workflows
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../enterprise/parallel/dispatch_manager/">
<span class="md-ellipsis">
    enterprise
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../models/aliases/">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../usage_tracking/collector/">
<span class="md-ellipsis">
    usage_tracking
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../quickstart/docker/">
<span class="md-ellipsis">
    Running With Docker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../quickstart/docker_configuration_options/">
<span class="md-ellipsis">
    Docker Configuration Options
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../quickstart/inference_gpu_windows/">
<span class="md-ellipsis">
    Install “bare metal” Inference GPU on Windows
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../contributing/">
<span class="md-ellipsis">
    Contribute to Inference
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="https://github.com/roboflow/inference/releases">
<span class="md-ellipsis">
    Changelog
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../cookbooks/">
<span class="md-ellipsis">
    Cookbooks
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow">
<span class="md-ellipsis">
      roboflow
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowCoreModel">
<span class="md-ellipsis">
      OnnxRoboflowCoreModel
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel">
<span class="md-ellipsis">
      OnnxRoboflowInferenceModel
    </span>
</a>
<nav aria-label="OnnxRoboflowInferenceModel" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.weights_file">
<span class="md-ellipsis">
      weights_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.__init__">
<span class="md-ellipsis">
      __init__
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.get_infer_bucket_file_list">
<span class="md-ellipsis">
      get_infer_bucket_file_list
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.infer">
<span class="md-ellipsis">
      infer
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.initialize_model">
<span class="md-ellipsis">
      initialize_model
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel">
<span class="md-ellipsis">
      RoboflowCoreModel
    </span>
</a>
<nav aria-label="RoboflowCoreModel" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.weights_file">
<span class="md-ellipsis">
      weights_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.__init__">
<span class="md-ellipsis">
      __init__
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.download_weights">
<span class="md-ellipsis">
      download_weights
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.get_device_id">
<span class="md-ellipsis">
      get_device_id
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.get_infer_bucket_file_list">
<span class="md-ellipsis">
      get_infer_bucket_file_list
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowCoreModel.preprocess_image">
<span class="md-ellipsis">
      preprocess_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel">
<span class="md-ellipsis">
      RoboflowInferenceModel
    </span>
</a>
<nav aria-label="RoboflowInferenceModel" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.weights_file">
<span class="md-ellipsis">
      weights_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.__init__">
<span class="md-ellipsis">
      __init__
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.cache_file">
<span class="md-ellipsis">
      cache_file
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.clear_cache">
<span class="md-ellipsis">
      clear_cache
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.draw_predictions">
<span class="md-ellipsis">
      draw_predictions
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_device_id">
<span class="md-ellipsis">
      get_device_id
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_infer_bucket_file_list">
<span class="md-ellipsis">
      get_infer_bucket_file_list
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_model_artifacts">
<span class="md-ellipsis">
      get_model_artifacts
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.initialize_model">
<span class="md-ellipsis">
      initialize_model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.preproc_image">
<span class="md-ellipsis">
      preproc_image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.models.roboflow.RoboflowInferenceModel.preprocess_image">
<span class="md-ellipsis">
      preprocess_image
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1>roboflow</h1>
<div class="doc doc-object doc-module">
<a id="inference.core.models.roboflow"></a>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="inference.core.models.roboflow.OnnxRoboflowCoreModel">
<code>OnnxRoboflowCoreModel</code>
<a class="headerlink" href="#inference.core.models.roboflow.OnnxRoboflowCoreModel" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="inference.core.models.roboflow.RoboflowCoreModel" href="#inference.core.models.roboflow.RoboflowCoreModel">RoboflowCoreModel</a></code></p>
<p>Roboflow Inference Model that operates using an ONNX model file.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">OnnxRoboflowCoreModel</span><span class="p">(</span><span class="n">RoboflowCoreModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Roboflow Inference Model that operates using an ONNX model file."""</span>

    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="inference.core.models.roboflow.OnnxRoboflowInferenceModel">
<code>OnnxRoboflowInferenceModel</code>
<a class="headerlink" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="inference.core.models.roboflow.RoboflowInferenceModel" href="#inference.core.models.roboflow.RoboflowInferenceModel">RoboflowInferenceModel</a></code></p>
<p>Roboflow Inference Model that operates using an ONNX model file.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">OnnxRoboflowInferenceModel</span><span class="p">(</span><span class="n">RoboflowInferenceModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Roboflow Inference Model that operates using an ONNX model file."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">onnxruntime_execution_providers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
            <span class="nb">str</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">get_onnxruntime_execution_providers</span><span class="p">(</span><span class="n">ONNXRUNTIME_EXECUTION_PROVIDERS</span><span class="p">),</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initializes the OnnxRoboflowInferenceModel instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier for the specific ONNX model.</span>
<span class="sd">            *args: Variable length argument list.</span>
<span class="sd">            **kwargs: Arbitrary keyword arguments.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_model_metadata</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span> <span class="o">=</span> <span class="n">onnxruntime_execution_providers</span>
            <span class="n">expanded_execution_providers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">ep</span> <span class="o">==</span> <span class="s2">"TensorrtExecutionProvider"</span><span class="p">:</span>
                    <span class="n">ep</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="s2">"TensorrtExecutionProvider"</span><span class="p">,</span>
                        <span class="p">{</span>
                            <span class="s2">"trt_engine_cache_enable"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                            <span class="s2">"trt_engine_cache_path"</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                                <span class="n">TENSORRT_CACHE_PATH</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span>
                            <span class="p">),</span>
                            <span class="s2">"trt_fp16_enable"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                        <span class="p">},</span>
                    <span class="p">)</span>
                <span class="n">expanded_execution_providers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ep</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span> <span class="o">=</span> <span class="n">expanded_execution_providers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_loader_threadpool</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">validate_model</span><span class="p">()</span>
        <span class="k">except</span> <span class="n">ModelArtefactError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unable to validate model artifacts, clearing cache: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span> <span class="kn">from</span> <span class="nn">e</span>

    <span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Runs inference on given data.</span>
<span class="sd">        - image:</span>
<span class="sd">            can be a BGR numpy array, filepath, InferenceRequestImage, PIL Image, byte-string, etc.</span>
<span class="sd">        """</span>
        <span class="n">input_elements</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">MAX_BATCH_SIZE</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">input_elements</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_batch_size</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)):</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Inference will be executed in batches, as there is </span><span class="si">{</span><span class="n">input_elements</span><span class="si">}</span><span class="s2"> input elements and "</span>
            <span class="sa">f</span><span class="s2">"maximum batch size for a model is set to: </span><span class="si">{</span><span class="n">max_batch_size</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span>
        <span class="n">inference_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">batch_input</span> <span class="ow">in</span> <span class="n">create_batches</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">max_batch_size</span><span class="p">):</span>
            <span class="n">batch_inference_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">batch_input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">inference_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_inference_results</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge_inference_results</span><span class="p">(</span><span class="n">inference_results</span><span class="o">=</span><span class="n">inference_results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">merge_inference_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inference_results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">inference_results</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">validate_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">MODEL_VALIDATION_DISABLED</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Model validation disabled."</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Starting model validation"</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnx_session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="s2">"ONNX session not initialized. Check that the model weights are available."</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">run_test_inference</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unable to run test inference. Cause: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">validate_model_classes</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Unable to validate model classes. Cause: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Model validation finished"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run_test_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">test_image</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Running test inference. Image size: </span><span class="si">{</span><span class="n">test_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">test_image</span><span class="p">,</span> <span class="n">usage_inference_test_run</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test inference finished."</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">get_model_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="n">test_image</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Getting model output shape. Image size: </span><span class="si">{</span><span class="n">test_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">test_image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_image</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model output shape test finished."</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">def</span> <span class="nf">validate_model_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">get_infer_bucket_file_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Returns the list of files to be downloaded from the inference bucket for ONNX model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: A list of filenames specific to ONNX models.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">"environment.json"</span><span class="p">,</span> <span class="s2">"class_names.txt"</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">initialize_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Initializes the ONNX model, setting up the inference session and other necessary properties."""</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Getting model artefacts"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_model_artifacts</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Creating inference session"</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_model_metadata</span><span class="p">:</span>
            <span class="n">t1_session</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
            <span class="c1"># Create an ONNX Runtime Session with a list of execution providers in priority order. ORT attempts to load providers until one is successful. This keeps the code across devices identical.</span>
            <span class="n">providers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span><span class="p">:</span>
                <span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"OpenVINOExecutionProvider"</span><span class="p">,</span> <span class="s2">"CPUExecutionProvider"</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">session_options</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">SessionOptions</span><span class="p">()</span>
                <span class="c1"># TensorRT does better graph optimization for its EP than onnx</span>
                <span class="k">if</span> <span class="n">has_trt</span><span class="p">(</span><span class="n">providers</span><span class="p">):</span>
                    <span class="n">session_options</span><span class="o">.</span><span class="n">graph_optimization_level</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">onnxruntime</span><span class="o">.</span><span class="n">GraphOptimizationLevel</span><span class="o">.</span><span class="n">ORT_DISABLE_ALL</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">onnx_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cache_file</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="p">),</span>
                    <span class="n">providers</span><span class="o">=</span><span class="n">providers</span><span class="p">,</span>
                    <span class="n">sess_options</span><span class="o">=</span><span class="n">session_options</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
                <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Unable to load ONNX session. Cause: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span>
                <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Session created in </span><span class="si">{</span><span class="n">perf_counter</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_session</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">REQUIRED_ONNX_PROVIDERS</span><span class="p">:</span>
                <span class="n">available_providers</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">get_available_providers</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">provider</span> <span class="ow">in</span> <span class="n">REQUIRED_ONNX_PROVIDERS</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">provider</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">available_providers</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">OnnxProviderNotAvailable</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">"Required ONNX Execution Provider </span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2"> is not availble. "</span>
                            <span class="s2">"Check that you are using the correct docker image on a supported device. "</span>
                            <span class="s2">"Export list of available providers as ONNXRUNTIME_EXECUTION_PROVIDERS environmental variable, "</span>
                            <span class="s2">"consult documentation for more details."</span>
                        <span class="p">)</span>

            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnx_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_name</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">name</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">if</span> <span class="s2">"resize"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">[</span><span class="s2">"resize"</span><span class="p">][</span><span class="s2">"height"</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">[</span><span class="s2">"resize"</span><span class="p">][</span><span class="s2">"width"</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="mi">640</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="mi">640</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching enabled"</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching disabled"</span>
                <span class="p">)</span>

            <span class="n">model_metadata</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">"batch_size"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="s2">"img_size_h"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">,</span>
                <span class="s2">"img_size_w"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Writing model metadata to memcache"</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">write_model_metadata_to_memcache</span><span class="p">(</span><span class="n">model_metadata</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span><span class="p">:</span>  <span class="c1"># had to load weights to get metadata</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnx_session</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_model_metadata</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">"This should be unreachable, should get weights if we don't have model metadata"</span>
                <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loading model metadata from memcache"</span><span class="p">)</span>
            <span class="n">metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_metadata_from_memcache</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"img_size_h"</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"img_size_w"</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching enabled"</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching disabled"</span>
                <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Model initialisation finished."</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">disable_preproc_auto_orient</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_contrast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_grayscale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_static_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">preproc_image</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preproc_image</span><span class="p">,</span>
                <span class="n">disable_preproc_auto_orient</span><span class="o">=</span><span class="n">disable_preproc_auto_orient</span><span class="p">,</span>
                <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="n">disable_preproc_contrast</span><span class="p">,</span>
                <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="n">disable_preproc_grayscale</span><span class="p">,</span>
                <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="n">disable_preproc_static_crop</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">imgs_with_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_loader_threadpool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preproc_image</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">img_dims</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">imgs_with_dims</span><span class="p">)</span>
            <span class="n">img_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">img_in</span><span class="p">,</span> <span class="n">img_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc_image</span><span class="p">(</span>
                <span class="n">image</span><span class="p">,</span>
                <span class="n">disable_preproc_auto_orient</span><span class="o">=</span><span class="n">disable_preproc_auto_orient</span><span class="p">,</span>
                <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="n">disable_preproc_contrast</span><span class="p">,</span>
                <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="n">disable_preproc_grayscale</span><span class="p">,</span>
                <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="n">disable_preproc_static_crop</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">img_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">img_dims</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">img_in</span><span class="p">,</span> <span class="n">img_dims</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights_file</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Returns the file containing the ONNX model weights.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The file path to the weights file.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="s2">"weights.onnx"</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.OnnxRoboflowInferenceModel.weights_file">
<code class="highlight language-python"><span class="n">weights_file</span><span class="p">:</span> <span class="nb">str</span></code>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-property"><code>property</code></small>
</span>
<a class="headerlink" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.weights_file" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Returns the file containing the ONNX model weights.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>str</code></td> <td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>The file path to the weights file.</p>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.OnnxRoboflowInferenceModel.__init__">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">onnxruntime_execution_providers</span><span class="o">=</span><span class="n">get_onnxruntime_execution_providers</span><span class="p">(</span><span class="n">ONNXRUNTIME_EXECUTION_PROVIDERS</span><span class="p">),</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.__init__" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Initializes the OnnxRoboflowInferenceModel instance.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>model_id</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>The identifier for the specific ONNX model.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>*args</code>
</td>
<td>
</td>
<td>
<div class="doc-md-description">
<p>Variable length argument list.</p>
</div>
</td>
<td>
<code>()</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>**kwargs</code>
</td>
<td>
</td>
<td>
<div class="doc-md-description">
<p>Arbitrary keyword arguments.</p>
</div>
</td>
<td>
<code>{}</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">onnxruntime_execution_providers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
        <span class="nb">str</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">get_onnxruntime_execution_providers</span><span class="p">(</span><span class="n">ONNXRUNTIME_EXECUTION_PROVIDERS</span><span class="p">),</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Initializes the OnnxRoboflowInferenceModel instance.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier for the specific ONNX model.</span>
<span class="sd">        *args: Variable length argument list.</span>
<span class="sd">        **kwargs: Arbitrary keyword arguments.</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_model_metadata</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span> <span class="o">=</span> <span class="n">onnxruntime_execution_providers</span>
        <span class="n">expanded_execution_providers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ep</span> <span class="o">==</span> <span class="s2">"TensorrtExecutionProvider"</span><span class="p">:</span>
                <span class="n">ep</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">"TensorrtExecutionProvider"</span><span class="p">,</span>
                    <span class="p">{</span>
                        <span class="s2">"trt_engine_cache_enable"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                        <span class="s2">"trt_engine_cache_path"</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                            <span class="n">TENSORRT_CACHE_PATH</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span>
                        <span class="p">),</span>
                        <span class="s2">"trt_fp16_enable"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">)</span>
            <span class="n">expanded_execution_providers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ep</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span> <span class="o">=</span> <span class="n">expanded_execution_providers</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">initialize_model</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_loader_threadpool</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validate_model</span><span class="p">()</span>
    <span class="k">except</span> <span class="n">ModelArtefactError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unable to validate model artifacts, clearing cache: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
        <span class="k">raise</span> <span class="n">ModelArtefactError</span> <span class="kn">from</span> <span class="nn">e</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.OnnxRoboflowInferenceModel.get_infer_bucket_file_list">
<code class="highlight language-python"><span class="n">get_infer_bucket_file_list</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.get_infer_bucket_file_list" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Returns the list of files to be downloaded from the inference bucket for ONNX model.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>list</code></td> <td>
<code>list</code>
</td>
<td>
<div class="doc-md-description">
<p>A list of filenames specific to ONNX models.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_infer_bucket_file_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Returns the list of files to be downloaded from the inference bucket for ONNX model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: A list of filenames specific to ONNX models.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="p">[</span><span class="s2">"environment.json"</span><span class="p">,</span> <span class="s2">"class_names.txt"</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.OnnxRoboflowInferenceModel.infer">
<code class="highlight language-python"><span class="n">infer</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.infer" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Runs inference on given data.
- image:
    can be a BGR numpy array, filepath, InferenceRequestImage, PIL Image, byte-string, etc.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Runs inference on given data.</span>
<span class="sd">    - image:</span>
<span class="sd">        can be a BGR numpy array, filepath, InferenceRequestImage, PIL Image, byte-string, etc.</span>
<span class="sd">    """</span>
    <span class="n">input_elements</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">MAX_BATCH_SIZE</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">input_elements</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_batch_size</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">"Inference will be executed in batches, as there is </span><span class="si">{</span><span class="n">input_elements</span><span class="si">}</span><span class="s2"> input elements and "</span>
        <span class="sa">f</span><span class="s2">"maximum batch size for a model is set to: </span><span class="si">{</span><span class="n">max_batch_size</span><span class="si">}</span><span class="s2">"</span>
    <span class="p">)</span>
    <span class="n">inference_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">batch_input</span> <span class="ow">in</span> <span class="n">create_batches</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">max_batch_size</span><span class="p">):</span>
        <span class="n">batch_inference_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">batch_input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">inference_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_inference_results</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">merge_inference_results</span><span class="p">(</span><span class="n">inference_results</span><span class="o">=</span><span class="n">inference_results</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.OnnxRoboflowInferenceModel.initialize_model">
<code class="highlight language-python"><span class="n">initialize_model</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.OnnxRoboflowInferenceModel.initialize_model" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Initializes the ONNX model, setting up the inference session and other necessary properties.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">initialize_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Initializes the ONNX model, setting up the inference session and other necessary properties."""</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Getting model artefacts"</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">get_model_artifacts</span><span class="p">()</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Creating inference session"</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_model_metadata</span><span class="p">:</span>
        <span class="n">t1_session</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
        <span class="c1"># Create an ONNX Runtime Session with a list of execution providers in priority order. ORT attempts to load providers until one is successful. This keeps the code across devices identical.</span>
        <span class="n">providers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnxruntime_execution_providers</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span><span class="p">:</span>
            <span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"OpenVINOExecutionProvider"</span><span class="p">,</span> <span class="s2">"CPUExecutionProvider"</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">session_options</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">SessionOptions</span><span class="p">()</span>
            <span class="c1"># TensorRT does better graph optimization for its EP than onnx</span>
            <span class="k">if</span> <span class="n">has_trt</span><span class="p">(</span><span class="n">providers</span><span class="p">):</span>
                <span class="n">session_options</span><span class="o">.</span><span class="n">graph_optimization_level</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">onnxruntime</span><span class="o">.</span><span class="n">GraphOptimizationLevel</span><span class="o">.</span><span class="n">ORT_DISABLE_ALL</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">onnx_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cache_file</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="p">),</span>
                <span class="n">providers</span><span class="o">=</span><span class="n">providers</span><span class="p">,</span>
                <span class="n">sess_options</span><span class="o">=</span><span class="n">session_options</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Unable to load ONNX session. Cause: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Session created in </span><span class="si">{</span><span class="n">perf_counter</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t1_session</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">REQUIRED_ONNX_PROVIDERS</span><span class="p">:</span>
            <span class="n">available_providers</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">get_available_providers</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">provider</span> <span class="ow">in</span> <span class="n">REQUIRED_ONNX_PROVIDERS</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">provider</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">available_providers</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">OnnxProviderNotAvailable</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">"Required ONNX Execution Provider </span><span class="si">{</span><span class="n">provider</span><span class="si">}</span><span class="s2"> is not availble. "</span>
                        <span class="s2">"Check that you are using the correct docker image on a supported device. "</span>
                        <span class="s2">"Export list of available providers as ONNXRUNTIME_EXECUTION_PROVIDERS environmental variable, "</span>
                        <span class="s2">"consult documentation for more details."</span>
                    <span class="p">)</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnx_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_name</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">name</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="s2">"resize"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">[</span><span class="s2">"resize"</span><span class="p">][</span><span class="s2">"height"</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">[</span><span class="s2">"resize"</span><span class="p">][</span><span class="s2">"width"</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="mi">640</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="mi">640</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching enabled"</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching disabled"</span>
            <span class="p">)</span>

        <span class="n">model_metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"batch_size"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="s2">"img_size_h"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">,</span>
            <span class="s2">"img_size_w"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Writing model metadata to memcache"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_model_metadata_to_memcache</span><span class="p">(</span><span class="n">model_metadata</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span><span class="p">:</span>  <span class="c1"># had to load weights to get metadata</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">onnx_session</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_model_metadata</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"This should be unreachable, should get weights if we don't have model metadata"</span>
            <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loading model metadata from memcache"</span><span class="p">)</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_metadata_from_memcache</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"img_size_h"</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"img_size_w"</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching enabled"</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batching_enabled</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2"> is loaded with dynamic batching disabled"</span>
            <span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Model initialisation finished."</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowCoreModel">
<code>RoboflowCoreModel</code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowCoreModel" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="inference.core.models.roboflow.RoboflowInferenceModel" href="#inference.core.models.roboflow.RoboflowInferenceModel">RoboflowInferenceModel</a></code></p>
<p>Base Roboflow inference model (Inherits from CvModel since all Roboflow models are CV models currently).</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">RoboflowCoreModel</span><span class="p">(</span><span class="n">RoboflowInferenceModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Base Roboflow inference model (Inherits from CvModel since all Roboflow models are CV models currently)."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""Initializes the RoboflowCoreModel instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The identifier for the specific model.</span>
<span class="sd">            api_key ([type], optional): The API key for authentication. Defaults to None.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">download_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">download_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Downloads the model weights from the configured source.</span>

<span class="sd">        This method includes handling for AWS access keys and error handling.</span>
<span class="sd">        """</span>
        <span class="n">infer_bucket_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_infer_bucket_file_list</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">are_all_files_cached</span><span class="p">(</span><span class="n">files</span><span class="o">=</span><span class="n">infer_bucket_files</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Model artifacts already downloaded, loading from cache"</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">is_model_artefacts_bucket_available</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">download_model_artefacts_from_s3</span><span class="p">()</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">download_model_from_roboflow_api</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">download_model_from_roboflow_api</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">api_data</span> <span class="o">=</span> <span class="n">get_roboflow_model_data</span><span class="p">(</span>
            <span class="n">api_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_key</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="n">endpoint_type</span><span class="o">=</span><span class="n">ModelEndpointType</span><span class="o">.</span><span class="n">CORE_MODEL</span><span class="p">,</span>
            <span class="n">device_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"weights"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">api_data</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"`weights` key not available in Roboflow API response while downloading model weights."</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">weights_url_key</span> <span class="ow">in</span> <span class="n">api_data</span><span class="p">[</span><span class="s2">"weights"</span><span class="p">]:</span>
            <span class="n">weights_url</span> <span class="o">=</span> <span class="n">api_data</span><span class="p">[</span><span class="s2">"weights"</span><span class="p">][</span><span class="n">weights_url_key</span><span class="p">]</span>
            <span class="n">t1</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
            <span class="n">model_weights_response</span> <span class="o">=</span> <span class="n">get_from_url</span><span class="p">(</span><span class="n">weights_url</span><span class="p">,</span> <span class="n">json_response</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">weights_url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"?"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">save_bytes_in_cache</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="n">model_weights_response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
                <span class="n">file</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t1</span> <span class="o">&gt;</span> <span class="mi">120</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s2">"Weights download took longer than 120 seconds, refreshing API request"</span>
                <span class="p">)</span>
                <span class="n">api_data</span> <span class="o">=</span> <span class="n">get_roboflow_model_data</span><span class="p">(</span>
                    <span class="n">api_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_key</span><span class="p">,</span>
                    <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
                    <span class="n">endpoint_type</span><span class="o">=</span><span class="n">ModelEndpointType</span><span class="o">.</span><span class="n">CORE_MODEL</span><span class="p">,</span>
                    <span class="n">device_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_id</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Returns the device ID associated with this model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The device ID.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span>

    <span class="k">def</span> <span class="nf">get_infer_bucket_file_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Abstract method to get the list of files to be downloaded from the inference bucket.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: This method must be implemented in subclasses.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[str]: A list of filenames.</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">"get_infer_bucket_file_list not implemented for OnnxRoboflowCoreModel"</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">preprocess_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Abstract method to preprocess an image.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: This method must be implemented in subclasses.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Image.Image: The preprocessed PIL image.</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">".preprocess_image"</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights_file</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Abstract property representing the file containing the model weights. For core models, all model artifacts are handled through get_infer_bucket_file_list method."""</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_artifact_bucket</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">CORE_MODEL_BUCKET</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowCoreModel.weights_file">
<code class="highlight language-python"><span class="n">weights_file</span><span class="p">:</span> <span class="nb">str</span></code>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-property"><code>property</code></small>
</span>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowCoreModel.weights_file" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Abstract property representing the file containing the model weights. For core models, all model artifacts are handled through get_infer_bucket_file_list method.</p>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowCoreModel.__init__">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowCoreModel.__init__" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Initializes the RoboflowCoreModel instance.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>model_id</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>The identifier for the specific model.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>api_key</code>
</td>
<td>
<code>[type]</code>
</td>
<td>
<div class="doc-md-description">
<p>The API key for authentication. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Initializes the RoboflowCoreModel instance.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The identifier for the specific model.</span>
<span class="sd">        api_key ([type], optional): The API key for authentication. Defaults to None.</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">download_weights</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowCoreModel.download_weights">
<code class="highlight language-python"><span class="n">download_weights</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowCoreModel.download_weights" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Downloads the model weights from the configured source.</p>
<p>This method includes handling for AWS access keys and error handling.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">download_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Downloads the model weights from the configured source.</span>

<span class="sd">    This method includes handling for AWS access keys and error handling.</span>
<span class="sd">    """</span>
    <span class="n">infer_bucket_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_infer_bucket_file_list</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">are_all_files_cached</span><span class="p">(</span><span class="n">files</span><span class="o">=</span><span class="n">infer_bucket_files</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Model artifacts already downloaded, loading from cache"</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">is_model_artefacts_bucket_available</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">download_model_artefacts_from_s3</span><span class="p">()</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">download_model_from_roboflow_api</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowCoreModel.get_device_id">
<code class="highlight language-python"><span class="n">get_device_id</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowCoreModel.get_device_id" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Returns the device ID associated with this model.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>str</code></td> <td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>The device ID.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Returns the device ID associated with this model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: The device ID.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowCoreModel.get_infer_bucket_file_list">
<code class="highlight language-python"><span class="n">get_infer_bucket_file_list</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowCoreModel.get_infer_bucket_file_list" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Abstract method to get the list of files to be downloaded from the inference bucket.</p>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>NotImplementedError</code>
</td>
<td>
<div class="doc-md-description">
<p>This method must be implemented in subclasses.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="typing.List">List</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>List[str]: A list of filenames.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_infer_bucket_file_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Abstract method to get the list of files to be downloaded from the inference bucket.</span>

<span class="sd">    Raises:</span>
<span class="sd">        NotImplementedError: This method must be implemented in subclasses.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[str]: A list of filenames.</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
        <span class="s2">"get_infer_bucket_file_list not implemented for OnnxRoboflowCoreModel"</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowCoreModel.preprocess_image">
<code class="highlight language-python"><span class="n">preprocess_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowCoreModel.preprocess_image" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Abstract method to preprocess an image.</p>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>NotImplementedError</code>
</td>
<td>
<div class="doc-md-description">
<p>This method must be implemented in subclasses.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="PIL.Image.Image">Image</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Image.Image: The preprocessed PIL image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">preprocess_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Abstract method to preprocess an image.</span>

<span class="sd">    Raises:</span>
<span class="sd">        NotImplementedError: This method must be implemented in subclasses.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Image.Image: The preprocessed PIL image.</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">".preprocess_image"</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel">
<code>RoboflowInferenceModel</code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="inference.core.models.base.Model" href="../base/#inference.core.models.base.Model">Model</a></code></p>
<p>Base Roboflow inference model.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">RoboflowInferenceModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Base Roboflow inference model."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">cache_dir_root</span><span class="o">=</span><span class="n">MODEL_CACHE_DIR</span><span class="p">,</span>
        <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">load_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initialize the RoboflowInferenceModel object.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): The unique identifier for the model.</span>
<span class="sd">            cache_dir_root (str, optional): The root directory for the cache. Defaults to MODEL_CACHE_DIR.</span>
<span class="sd">            api_key (str, optional): API key for authentication. Defaults to None.</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span> <span class="o">=</span> <span class="n">load_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"num_inferences"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"avg_inference_time"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key</span> <span class="k">if</span> <span class="n">api_key</span> <span class="k">else</span> <span class="n">API_KEY</span>
        <span class="n">model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_id</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">version_id</span> <span class="o">=</span> <span class="n">model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span> <span class="o">=</span> <span class="n">model_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="n">GLOBAL_DEVICE_ID</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir_root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keypoints_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">initialise_cache</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cache_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Get the cache file path for a given file.</span>

<span class="sd">        Args:</span>
<span class="sd">            f (str): Filename.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Full path to the cached file.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">get_cache_file_path</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">clear_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Clear the cache directory."""</span>
        <span class="n">clear_cache</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">draw_predictions</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inference_request</span><span class="p">:</span> <span class="n">InferenceRequest</span><span class="p">,</span>
        <span class="n">inference_response</span><span class="p">:</span> <span class="n">InferenceResponse</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Draw predictions from an inference response onto the original image provided by an inference request</span>

<span class="sd">        Args:</span>
<span class="sd">            inference_request (ObjectDetectionInferenceRequest): The inference request containing the image on which to draw predictions</span>
<span class="sd">            inference_response (ObjectDetectionInferenceResponse): The inference response containing predictions to be drawn</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: A base64 encoded image string</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">draw_detection_predictions</span><span class="p">(</span>
            <span class="n">inference_request</span><span class="o">=</span><span class="n">inference_request</span><span class="p">,</span>
            <span class="n">inference_response</span><span class="o">=</span><span class="n">inference_response</span><span class="p">,</span>
            <span class="n">colors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">colors</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">get_class_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span>

    <span class="k">def</span> <span class="nf">get_device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Get the device identifier on which the model is deployed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: Device identifier.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span>

    <span class="k">def</span> <span class="nf">get_infer_bucket_file_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Get a list of inference bucket files.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: If the method is not implemented.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[str]: A list of inference bucket files.</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">".get_infer_bucket_file_list"</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cache_key</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">"metadata:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2">"</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">model_metadata_from_memcache_endpoint</span><span class="p">(</span><span class="n">endpoint</span><span class="p">):</span>
        <span class="n">model_metadata</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">"metadata:</span><span class="si">{</span><span class="n">endpoint</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_metadata</span>

    <span class="k">def</span> <span class="nf">model_metadata_from_memcache</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">model_metadata</span> <span class="o">=</span> <span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_metadata</span>

    <span class="k">def</span> <span class="nf">write_model_metadata_to_memcache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
        <span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_key</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">expire</span><span class="o">=</span><span class="n">MODEL_METADATA_CACHE_EXPIRATION_TIMEOUT</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">has_model_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_metadata_from_memcache</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">get_model_artifacts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Fetch or load the model artifacts.</span>

<span class="sd">        Downloads the model artifacts from S3 or the Roboflow API if they are not already cached.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_model_artefacts</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_model_artifacts_from_cache</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">cache_model_artefacts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">infer_bucket_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_all_required_infer_bucket_file</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">are_all_files_cached</span><span class="p">(</span><span class="n">files</span><span class="o">=</span><span class="n">infer_bucket_files</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">is_model_artefacts_bucket_available</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">download_model_artefacts_from_s3</span><span class="p">()</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">download_model_artifacts_from_roboflow_api</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_all_required_infer_bucket_file</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">infer_bucket_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_infer_bucket_file_list</span><span class="p">()</span>
        <span class="n">infer_bucket_files</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"List of files required to load model: </span><span class="si">{</span><span class="n">infer_bucket_files</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">infer_bucket_files</span> <span class="k">if</span> <span class="n">f</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">download_model_artefacts_from_s3</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Downloading model artifacts from S3"</span><span class="p">)</span>
            <span class="n">infer_bucket_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_all_required_infer_bucket_file</span><span class="p">()</span>
            <span class="n">cache_directory</span> <span class="o">=</span> <span class="n">get_cache_dir</span><span class="p">()</span>
            <span class="n">s3_keys</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">file</span><span class="si">}</span><span class="s2">"</span> <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">infer_bucket_files</span><span class="p">]</span>
            <span class="n">download_s3_files_to_directory</span><span class="p">(</span>
                <span class="n">bucket</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_artifact_bucket</span><span class="p">,</span>
                <span class="n">keys</span><span class="o">=</span><span class="n">s3_keys</span><span class="p">,</span>
                <span class="n">target_dir</span><span class="o">=</span><span class="n">cache_directory</span><span class="p">,</span>
                <span class="n">s3_client</span><span class="o">=</span><span class="n">S3_CLIENT</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Could not obtain model artefacts from S3 with keys </span><span class="si">{</span><span class="n">s3_keys</span><span class="si">}</span><span class="s2">. Cause: </span><span class="si">{</span><span class="n">error</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">error</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_artifact_bucket</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">INFER_BUCKET</span>

    <span class="k">def</span> <span class="nf">download_model_artifacts_from_roboflow_api</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Downloading model artifacts from Roboflow API"</span><span class="p">)</span>
        <span class="n">api_data</span> <span class="o">=</span> <span class="n">get_roboflow_model_data</span><span class="p">(</span>
            <span class="n">api_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">api_key</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="n">endpoint_type</span><span class="o">=</span><span class="n">ModelEndpointType</span><span class="o">.</span><span class="n">ORT</span><span class="p">,</span>
            <span class="n">device_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"ort"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">api_data</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="s2">"Could not find `ort` key in roboflow API model description response."</span>
            <span class="p">)</span>
        <span class="n">api_data</span> <span class="o">=</span> <span class="n">api_data</span><span class="p">[</span><span class="s2">"ort"</span><span class="p">]</span>
        <span class="k">if</span> <span class="s2">"classes"</span> <span class="ow">in</span> <span class="n">api_data</span><span class="p">:</span>
            <span class="n">save_text_lines_in_cache</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="n">api_data</span><span class="p">[</span><span class="s2">"classes"</span><span class="p">],</span>
                <span class="n">file</span><span class="o">=</span><span class="s2">"class_names.txt"</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"model"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">api_data</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="s2">"Could not find `model` key in roboflow API model description response."</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"environment"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">api_data</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="s2">"Could not find `environment` key in roboflow API model description response."</span>
            <span class="p">)</span>
        <span class="n">environment</span> <span class="o">=</span> <span class="n">get_from_url</span><span class="p">(</span><span class="n">api_data</span><span class="p">[</span><span class="s2">"environment"</span><span class="p">])</span>
        <span class="n">model_weights_response</span> <span class="o">=</span> <span class="n">get_from_url</span><span class="p">(</span><span class="n">api_data</span><span class="p">[</span><span class="s2">"model"</span><span class="p">],</span> <span class="n">json_response</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">save_bytes_in_cache</span><span class="p">(</span>
            <span class="n">content</span><span class="o">=</span><span class="n">model_weights_response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
            <span class="n">file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"colors"</span> <span class="ow">in</span> <span class="n">api_data</span><span class="p">:</span>
            <span class="n">environment</span><span class="p">[</span><span class="s2">"COLORS"</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_data</span><span class="p">[</span><span class="s2">"colors"</span><span class="p">]</span>
        <span class="n">save_json_in_cache</span><span class="p">(</span>
            <span class="n">content</span><span class="o">=</span><span class="n">environment</span><span class="p">,</span>
            <span class="n">file</span><span class="o">=</span><span class="s2">"environment.json"</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"keypoints_metadata"</span> <span class="ow">in</span> <span class="n">api_data</span><span class="p">:</span>
            <span class="c1"># TODO: make sure backend provides that</span>
            <span class="n">save_json_in_cache</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="n">api_data</span><span class="p">[</span><span class="s2">"keypoints_metadata"</span><span class="p">],</span>
                <span class="n">file</span><span class="o">=</span><span class="s2">"keypoints_metadata.json"</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_model_artifacts_from_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"Model artifacts already downloaded, loading model from cache"</span><span class="p">)</span>
        <span class="n">infer_bucket_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_all_required_infer_bucket_file</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">"environment.json"</span> <span class="ow">in</span> <span class="n">infer_bucket_files</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">environment</span> <span class="o">=</span> <span class="n">load_json_from_cache</span><span class="p">(</span>
                <span class="n">file</span><span class="o">=</span><span class="s2">"environment.json"</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
                <span class="n">object_pairs_hook</span><span class="o">=</span><span class="n">OrderedDict</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"class_names.txt"</span> <span class="ow">in</span> <span class="n">infer_bucket_files</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">load_text_file_from_cache</span><span class="p">(</span>
                <span class="n">file</span><span class="o">=</span><span class="s2">"class_names.txt"</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
                <span class="n">split_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">strip_white_chars</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">get_class_names_from_environment_file</span><span class="p">(</span>
                <span class="n">environment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">environment</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">colors</span> <span class="o">=</span> <span class="n">get_color_mapping_from_environment</span><span class="p">(</span>
            <span class="n">environment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">environment</span><span class="p">,</span>
            <span class="n">class_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="s2">"keypoints_metadata.json"</span> <span class="ow">in</span> <span class="n">infer_bucket_files</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">keypoints_metadata</span> <span class="o">=</span> <span class="n">parse_keypoints_metadata</span><span class="p">(</span>
                <span class="n">load_json_from_cache</span><span class="p">(</span>
                    <span class="n">file</span><span class="o">=</span><span class="s2">"keypoints_metadata.json"</span><span class="p">,</span>
                    <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
                    <span class="n">object_pairs_hook</span><span class="o">=</span><span class="n">OrderedDict</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">"PREPROCESSING"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">environment</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ModelArtefactError</span><span class="p">(</span>
                <span class="s2">"Could not find `PREPROCESSING` key in environment file."</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">environment</span><span class="p">[</span><span class="s2">"PREPROCESSING"</span><span class="p">]),</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">environment</span><span class="p">[</span><span class="s2">"PREPROCESSING"</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">environment</span><span class="p">[</span><span class="s2">"PREPROCESSING"</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"resize"</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">[</span><span class="s2">"resize"</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"format"</span><span class="p">,</span> <span class="s2">"Stretch to"</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="s2">"Stretch to"</span><span class="p">,</span>
                <span class="s2">"Fit (black edges) in"</span><span class="p">,</span>
                <span class="s2">"Fit (white edges) in"</span><span class="p">,</span>
                <span class="s2">"Fit (grey edges) in"</span><span class="p">,</span>
            <span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">=</span> <span class="s2">"Stretch to"</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">=</span> <span class="s2">"Stretch to"</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Resize method is '</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span><span class="si">}</span><span class="s2">'"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiclass</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">environment</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"MULTICLASS"</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">initialize_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Initialize the model.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: If the method is not implemented.</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">".initialize_model"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">preproc_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">InferenceRequestImage</span><span class="p">],</span>
        <span class="n">disable_preproc_auto_orient</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_contrast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_grayscale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_static_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Preprocesses an inference request image by loading it, then applying any pre-processing specified by the Roboflow platform, then scaling it to the inference input dimensions.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (Union[Any, InferenceRequestImage]): An object containing information necessary to load the image for inference.</span>
<span class="sd">            disable_preproc_auto_orient (bool, optional): If true, the auto orient preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">            disable_preproc_contrast (bool, optional): If true, the contrast preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">            disable_preproc_grayscale (bool, optional): If true, the grayscale preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">            disable_preproc_static_crop (bool, optional): If true, the static crop preprocessing step is disabled for this call. Default is False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[np.ndarray, Tuple[int, int]]: A tuple containing a numpy array of the preprocessed image pixel data and a tuple of the images original size.</span>
<span class="sd">        """</span>
        <span class="n">np_image</span><span class="p">,</span> <span class="n">is_bgr</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="n">disable_preproc_auto_orient</span><span class="o">=</span><span class="n">disable_preproc_auto_orient</span>
            <span class="ow">or</span> <span class="s2">"auto-orient"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="ow">or</span> <span class="n">DISABLE_PREPROC_AUTO_ORIENT</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">preprocessed_image</span><span class="p">,</span> <span class="n">img_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_image</span><span class="p">(</span>
            <span class="n">np_image</span><span class="p">,</span>
            <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="n">disable_preproc_contrast</span><span class="p">,</span>
            <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="n">disable_preproc_grayscale</span><span class="p">,</span>
            <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="n">disable_preproc_static_crop</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Stretch to"</span><span class="p">:</span>
            <span class="n">resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span>
                <span class="n">preprocessed_image</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">INTER_CUBIC</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Fit (black edges) in"</span><span class="p">:</span>
            <span class="n">resized</span> <span class="o">=</span> <span class="n">letterbox_image</span><span class="p">(</span>
                <span class="n">preprocessed_image</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Fit (white edges) in"</span><span class="p">:</span>
            <span class="n">resized</span> <span class="o">=</span> <span class="n">letterbox_image</span><span class="p">(</span>
                <span class="n">preprocessed_image</span><span class="p">,</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">),</span>
                <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Fit (grey edges) in"</span><span class="p">:</span>
            <span class="n">resized</span> <span class="o">=</span> <span class="n">letterbox_image</span><span class="p">(</span>
                <span class="n">preprocessed_image</span><span class="p">,</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">),</span>
                <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">114</span><span class="p">,</span> <span class="mi">114</span><span class="p">,</span> <span class="mi">114</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_bgr</span><span class="p">:</span>
            <span class="n">resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">resized</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
        <span class="n">img_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">resized</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">img_in</span> <span class="o">=</span> <span class="n">img_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">img_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img_in</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">img_in</span><span class="p">,</span> <span class="n">img_dims</span>

    <span class="k">def</span> <span class="nf">preprocess_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">disable_preproc_contrast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_grayscale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">disable_preproc_static_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Preprocesses the given image using specified preprocessing steps.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (Image.Image): The PIL image to preprocess.</span>
<span class="sd">            disable_preproc_contrast (bool, optional): If true, the contrast preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">            disable_preproc_grayscale (bool, optional): If true, the grayscale preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">            disable_preproc_static_crop (bool, optional): If true, the static crop preprocessing step is disabled for this call. Default is False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Image.Image: The preprocessed PIL image.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">prepare</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">,</span>
            <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="n">disable_preproc_contrast</span><span class="p">,</span>
            <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="n">disable_preproc_grayscale</span><span class="p">,</span>
            <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="n">disable_preproc_static_crop</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights_file</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Abstract property representing the file containing the model weights.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: This property must be implemented in subclasses.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The file path to the weights file.</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">".weights_file"</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-attribute">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.weights_file">
<code class="highlight language-python"><span class="n">weights_file</span><span class="p">:</span> <span class="nb">str</span></code>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-property"><code>property</code></small>
</span>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.weights_file" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Abstract property representing the file containing the model weights.</p>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>NotImplementedError</code>
</td>
<td>
<div class="doc-md-description">
<p>This property must be implemented in subclasses.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>str</code></td> <td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>The file path to the weights file.</p>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.__init__">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">cache_dir_root</span><span class="o">=</span><span class="n">MODEL_CACHE_DIR</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">load_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.__init__" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Initialize the RoboflowInferenceModel object.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>model_id</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>The unique identifier for the model.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>cache_dir_root</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>The root directory for the cache. Defaults to MODEL_CACHE_DIR.</p>
</div>
</td>
<td>
<code><span title="inference.core.env.MODEL_CACHE_DIR">MODEL_CACHE_DIR</span></code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>api_key</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>API key for authentication. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">cache_dir_root</span><span class="o">=</span><span class="n">MODEL_CACHE_DIR</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">load_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize the RoboflowInferenceModel object.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): The unique identifier for the model.</span>
<span class="sd">        cache_dir_root (str, optional): The root directory for the cache. Defaults to MODEL_CACHE_DIR.</span>
<span class="sd">        api_key (str, optional): API key for authentication. Defaults to None.</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span> <span class="o">=</span> <span class="n">load_weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"num_inferences"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"avg_inference_time"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key</span> <span class="k">if</span> <span class="n">api_key</span> <span class="k">else</span> <span class="n">API_KEY</span>
    <span class="n">model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_id</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">version_id</span> <span class="o">=</span> <span class="n">model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span> <span class="o">=</span> <span class="n">model_id</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span> <span class="o">=</span> <span class="n">GLOBAL_DEVICE_ID</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir_root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">keypoints_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">initialise_cache</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.cache_file">
<code class="highlight language-python"><span class="n">cache_file</span><span class="p">(</span><span class="n">f</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.cache_file" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Get the cache file path for a given file.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>f</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>Filename.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>str</code></td> <td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>Full path to the cached file.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">cache_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Get the cache file path for a given file.</span>

<span class="sd">    Args:</span>
<span class="sd">        f (str): Filename.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Full path to the cached file.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">get_cache_file_path</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.clear_cache">
<code class="highlight language-python"><span class="n">clear_cache</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.clear_cache" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Clear the cache directory.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">clear_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Clear the cache directory."""</span>
    <span class="n">clear_cache</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">endpoint</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.draw_predictions">
<code class="highlight language-python"><span class="n">draw_predictions</span><span class="p">(</span><span class="n">inference_request</span><span class="p">,</span> <span class="n">inference_response</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.draw_predictions" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Draw predictions from an inference response onto the original image provided by an inference request</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>inference_request</code>
</td>
<td>
<code>ObjectDetectionInferenceRequest</code>
</td>
<td>
<div class="doc-md-description">
<p>The inference request containing the image on which to draw predictions</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>inference_response</code>
</td>
<td>
<code>ObjectDetectionInferenceResponse</code>
</td>
<td>
<div class="doc-md-description">
<p>The inference response containing predictions to be drawn</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>str</code></td> <td>
<code>bytes</code>
</td>
<td>
<div class="doc-md-description">
<p>A base64 encoded image string</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">draw_predictions</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inference_request</span><span class="p">:</span> <span class="n">InferenceRequest</span><span class="p">,</span>
    <span class="n">inference_response</span><span class="p">:</span> <span class="n">InferenceResponse</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Draw predictions from an inference response onto the original image provided by an inference request</span>

<span class="sd">    Args:</span>
<span class="sd">        inference_request (ObjectDetectionInferenceRequest): The inference request containing the image on which to draw predictions</span>
<span class="sd">        inference_response (ObjectDetectionInferenceResponse): The inference response containing predictions to be drawn</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: A base64 encoded image string</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">draw_detection_predictions</span><span class="p">(</span>
        <span class="n">inference_request</span><span class="o">=</span><span class="n">inference_request</span><span class="p">,</span>
        <span class="n">inference_response</span><span class="o">=</span><span class="n">inference_response</span><span class="p">,</span>
        <span class="n">colors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">colors</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.get_device_id">
<code class="highlight language-python"><span class="n">get_device_id</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_device_id" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Get the device identifier on which the model is deployed.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Name</th> <th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td><code>str</code></td> <td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>Device identifier.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_device_id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Get the device identifier on which the model is deployed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Device identifier.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_id</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.get_infer_bucket_file_list">
<code class="highlight language-python"><span class="n">get_infer_bucket_file_list</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_infer_bucket_file_list" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Get a list of inference bucket files.</p>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>NotImplementedError</code>
</td>
<td>
<div class="doc-md-description">
<p>If the method is not implemented.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="typing.List">List</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>List[str]: A list of inference bucket files.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_infer_bucket_file_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Get a list of inference bucket files.</span>

<span class="sd">    Raises:</span>
<span class="sd">        NotImplementedError: If the method is not implemented.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[str]: A list of inference bucket files.</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">".get_infer_bucket_file_list"</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.get_model_artifacts">
<code class="highlight language-python"><span class="n">get_model_artifacts</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.get_model_artifacts" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Fetch or load the model artifacts.</p>
<p>Downloads the model artifacts from S3 or the Roboflow API if they are not already cached.</p>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_model_artifacts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Fetch or load the model artifacts.</span>

<span class="sd">    Downloads the model artifacts from S3 or the Roboflow API if they are not already cached.</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cache_model_artefacts</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">load_model_artifacts_from_cache</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.initialize_model">
<code class="highlight language-python"><span class="n">initialize_model</span><span class="p">()</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.initialize_model" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Initialize the model.</p>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>NotImplementedError</code>
</td>
<td>
<div class="doc-md-description">
<p>If the method is not implemented.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">initialize_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Initialize the model.</span>

<span class="sd">    Raises:</span>
<span class="sd">        NotImplementedError: If the method is not implemented.</span>
<span class="sd">    """</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">".initialize_model"</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.preproc_image">
<code class="highlight language-python"><span class="n">preproc_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">disable_preproc_auto_orient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.preproc_image" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Preprocesses an inference request image by loading it, then applying any pre-processing specified by the Roboflow platform, then scaling it to the inference input dimensions.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>image</code>
</td>
<td>
<code><span title="typing.Union">Union</span>[<span title="typing.Any">Any</span>, <a class="autorefs autorefs-internal" title="inference.core.entities.requests.inference.InferenceRequestImage" href="../../entities/requests/inference/#inference.core.entities.requests.inference.InferenceRequestImage">InferenceRequestImage</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>An object containing information necessary to load the image for inference.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>disable_preproc_auto_orient</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If true, the auto orient preprocessing step is disabled for this call. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>disable_preproc_contrast</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If true, the contrast preprocessing step is disabled for this call. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>disable_preproc_grayscale</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If true, the grayscale preprocessing step is disabled for this call. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>disable_preproc_static_crop</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If true, the static crop preprocessing step is disabled for this call. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="typing.Tuple">Tuple</span>[<span title="numpy.ndarray">ndarray</span>, <span title="typing.Tuple">Tuple</span>[int, int]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Tuple[np.ndarray, Tuple[int, int]]: A tuple containing a numpy array of the preprocessed image pixel data and a tuple of the images original size.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">preproc_image</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">InferenceRequestImage</span><span class="p">],</span>
    <span class="n">disable_preproc_auto_orient</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_preproc_contrast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_preproc_grayscale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_preproc_static_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Preprocesses an inference request image by loading it, then applying any pre-processing specified by the Roboflow platform, then scaling it to the inference input dimensions.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (Union[Any, InferenceRequestImage]): An object containing information necessary to load the image for inference.</span>
<span class="sd">        disable_preproc_auto_orient (bool, optional): If true, the auto orient preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">        disable_preproc_contrast (bool, optional): If true, the contrast preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">        disable_preproc_grayscale (bool, optional): If true, the grayscale preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">        disable_preproc_static_crop (bool, optional): If true, the static crop preprocessing step is disabled for this call. Default is False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[np.ndarray, Tuple[int, int]]: A tuple containing a numpy array of the preprocessed image pixel data and a tuple of the images original size.</span>
<span class="sd">    """</span>
    <span class="n">np_image</span><span class="p">,</span> <span class="n">is_bgr</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">disable_preproc_auto_orient</span><span class="o">=</span><span class="n">disable_preproc_auto_orient</span>
        <span class="ow">or</span> <span class="s2">"auto-orient"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="ow">or</span> <span class="n">DISABLE_PREPROC_AUTO_ORIENT</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">preprocessed_image</span><span class="p">,</span> <span class="n">img_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_image</span><span class="p">(</span>
        <span class="n">np_image</span><span class="p">,</span>
        <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="n">disable_preproc_contrast</span><span class="p">,</span>
        <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="n">disable_preproc_grayscale</span><span class="p">,</span>
        <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="n">disable_preproc_static_crop</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Stretch to"</span><span class="p">:</span>
        <span class="n">resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span>
            <span class="n">preprocessed_image</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">INTER_CUBIC</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Fit (black edges) in"</span><span class="p">:</span>
        <span class="n">resized</span> <span class="o">=</span> <span class="n">letterbox_image</span><span class="p">(</span>
            <span class="n">preprocessed_image</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Fit (white edges) in"</span><span class="p">:</span>
        <span class="n">resized</span> <span class="o">=</span> <span class="n">letterbox_image</span><span class="p">(</span>
            <span class="n">preprocessed_image</span><span class="p">,</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">),</span>
            <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize_method</span> <span class="o">==</span> <span class="s2">"Fit (grey edges) in"</span><span class="p">:</span>
        <span class="n">resized</span> <span class="o">=</span> <span class="n">letterbox_image</span><span class="p">(</span>
            <span class="n">preprocessed_image</span><span class="p">,</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size_h</span><span class="p">),</span>
            <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">114</span><span class="p">,</span> <span class="mi">114</span><span class="p">,</span> <span class="mi">114</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">is_bgr</span><span class="p">:</span>
        <span class="n">resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">resized</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
    <span class="n">img_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">resized</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">img_in</span> <span class="o">=</span> <span class="n">img_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">img_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img_in</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">img_in</span><span class="p">,</span> <span class="n">img_dims</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.models.roboflow.RoboflowInferenceModel.preprocess_image">
<code class="highlight language-python"><span class="n">preprocess_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>
<a class="headerlink" href="#inference.core.models.roboflow.RoboflowInferenceModel.preprocess_image" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>Preprocesses the given image using specified preprocessing steps.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>image</code>
</td>
<td>
<code><span title="PIL.Image.Image">Image</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The PIL image to preprocess.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>disable_preproc_contrast</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If true, the contrast preprocessing step is disabled for this call. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>disable_preproc_grayscale</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If true, the grayscale preprocessing step is disabled for this call. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>disable_preproc_static_crop</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>If true, the static crop preprocessing step is disabled for this call. Default is False.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="typing.Tuple">Tuple</span>[<span title="numpy.ndarray">ndarray</span>, <span title="typing.Tuple">Tuple</span>[int, int]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Image.Image: The preprocessed PIL image.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>inference/core/models/roboflow.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">preprocess_image</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">disable_preproc_contrast</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_preproc_grayscale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_preproc_static_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Preprocesses the given image using specified preprocessing steps.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (Image.Image): The PIL image to preprocess.</span>
<span class="sd">        disable_preproc_contrast (bool, optional): If true, the contrast preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">        disable_preproc_grayscale (bool, optional): If true, the grayscale preprocessing step is disabled for this call. Default is False.</span>
<span class="sd">        disable_preproc_static_crop (bool, optional): If true, the static crop preprocessing step is disabled for this call. Default is False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Image.Image: The preprocessed PIL image.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">prepare</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">,</span>
        <span class="n">disable_preproc_contrast</span><span class="o">=</span><span class="n">disable_preproc_contrast</span><span class="p">,</span>
        <span class="n">disable_preproc_grayscale</span><span class="o">=</span><span class="n">disable_preproc_grayscale</span><span class="p">,</span>
        <span class="n">disable_preproc_static_crop</span><span class="o">=</span><span class="n">disable_preproc_static_crop</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: object_detection_base" class="md-footer__link md-footer__link--prev" href="../object_detection_base/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                object_detection_base
              </div>
</div>
</a>
<a aria-label="Next: stubs" class="md-footer__link md-footer__link--next" href="../stubs/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                stubs
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Roboflow 2024. All rights reserved.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/roboflow" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
<a class="md-social__link" href="https://www.youtube.com/roboflow" rel="noopener" target="_blank" title="www.youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/roboflow-ai/mycompany/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg>
</a>
<a class="md-social__link" href="https://twitter.com/roboflow" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../../../../..", "features": ["navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.indexes", "navigation.sections", "content.code.copy"], "search": "../../../../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": 1.0}}</script>
<script src="../../../../../../assets/javascripts/bundle.3220b9d7.min.js"></script>
<script src="https://widget.kapa.ai/kapa-widget.bundle.js"></script>
<script src="../../../../../../javascript/init_kapa_widget.js"></script>
<script src="../../../../../../javascript/cookbooks.js"></script>
<script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body>
</html>