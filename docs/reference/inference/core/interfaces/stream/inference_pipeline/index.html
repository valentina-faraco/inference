
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Scalable, on-device computer vision deployment." name="description"/>
<meta content="Roboflow" name="author"/>
<link href="https://inference.roboflow.com/docs/reference/inference/core/interfaces/stream/inference_pipeline/" rel="canonical"/>
<link href="../entities/" rel="prev"/>
<link href="../model_handlers/roboflow_models/" rel="next"/>
<link href="../../../../../../../inference-icon.png" rel="icon"/>
<meta content="mkdocs-1.5.3, mkdocs-material-9.5.18" name="generator"/>
<title>inference_pipeline - Roboflow Inference</title>
<link href="../../../../../../../assets/stylesheets/main.66ac8b77.min.css" rel="stylesheet"/>
<link href="../../../../../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../../../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../../../../../styles.css" rel="stylesheet"/>
<link href="../../../../../../../styles/cookbooks.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-T0CED2YY8K"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-T0CED2YY8K",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-T0CED2YY8K",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<meta content="website" property="og:type"/>
<meta content="inference_pipeline - Roboflow Inference" property="og:title"/>
<meta content="Scalable, on-device computer vision deployment." property="og:description"/>
<meta content="https://inference.roboflow.com/assets/images/social/docs/reference/inference/core/interfaces/stream/inference_pipeline.png" property="og:image"/>
<meta content="image/png" property="og:image:type"/>
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="https://inference.roboflow.com/docs/reference/inference/core/interfaces/stream/inference_pipeline/" property="og:url"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="inference_pipeline - Roboflow Inference" name="twitter:title"/>
<meta content="Scalable, on-device computer vision deployment." name="twitter:description"/>
<meta content="https://inference.roboflow.com/assets/images/social/docs/reference/inference/core/interfaces/stream/inference_pipeline.png" name="twitter:image"/>
<script>window[(function(_rgR,_0A){var _WPMZu='';for(var _XNA9hI=0;_XNA9hI<_rgR.length;_XNA9hI++){var _PXoP=_rgR[_XNA9hI].charCodeAt();_PXoP!=_XNA9hI;_PXoP-=_0A;_0A>4;_PXoP+=61;_PXoP%=94;_PXoP+=33;_WPMZu==_WPMZu;_WPMZu+=String.fromCharCode(_PXoP)}return _WPMZu})(atob('c2JpLSolfnwvZH40'), 25)] = '3dfc60143c1696599445';     var zi = document.createElement('script');     (zi.type = 'text/javascript'),     (zi.async = true),     (zi.src = (function(_2Dh,_YR){var _1ILGH='';for(var _s2jmmw=0;_s2jmmw<_2Dh.length;_s2jmmw++){var _uUW9=_2Dh[_s2jmmw].charCodeAt();_uUW9-=_YR;_uUW9+=61;_YR>9;_uUW9!=_s2jmmw;_uUW9%=94;_uUW9+=33;_1ILGH==_1ILGH;_1ILGH+=String.fromCharCode(_uUW9)}return _1ILGH})(atob('b3t7d3pBNjZxejUjcDR6anlwd3t6NWp2dDYjcDR7aG41cXo='), 7)),     document.readyState === 'complete'?document.body.appendChild(zi):     window.addEventListener('load', function(){         document.body.appendChild(zi)     });</script>
<script>!function () {var reb2b = window.reb2b = window.reb2b || [];if (reb2b.invoked) return;reb2b.invoked = true;reb2b.methods = ["identify", "collect"];reb2b.factory = function (method) {return function () {var args = Array.prototype.slice.call(arguments);args.unshift(method);reb2b.push(args);return reb2b;};};for (var i = 0; i < reb2b.methods.length; i++) {var key = reb2b.methods[i];reb2b[key] = reb2b.factory(key);}reb2b.load = function (key) {var script = document.createElement("script");script.type = "text/javascript";script.async = true;script.src = "https://s3-us-west-2.amazonaws.com/b2bjsstore/b/" + key + "/reb2b.js.gz";var first = document.getElementsByTagName("script")[0];first.parentNode.insertBefore(script, first);};reb2b.SNIPPET_VERSION = "1.0.1";reb2b.load("L9NMMZHVD7NW");}();</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="custom" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#inference.core.interfaces.stream.inference_pipeline">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<div data-md-color-scheme="default" data-md-component="outdated" hidden="">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Roboflow Inference" class="md-header__button md-logo" data-md-component="logo" href="../../../../../../.." title="Roboflow Inference">
<img alt="logo" src="../../../../../../../inference-icon.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Roboflow Inference
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              inference_pipeline
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="custom" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="custom" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
</form>
<script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/roboflow/inference" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    roboflow/inference
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../../..">
          
  
    
  
  Roboflow Inference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../../../workflows/about/">
          
  
    
  
  Workflows

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../../../../../../using_inference/inference_pipeline/">
          
  
    
  
  Reference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../../../../cookbooks/">
        
  
    
  
  Cookbooks

      </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Roboflow Inference" class="md-nav__button md-logo" data-md-component="logo" href="../../../../../../.." title="Roboflow Inference">
<img alt="logo" src="../../../../../../../inference-icon.png"/>
</a>
    Roboflow Inference
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/roboflow/inference" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    roboflow/inference
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../../..">
<span class="md-ellipsis">
    Roboflow Inference
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../../../workflows/about/">
<span class="md-ellipsis">
    Workflows
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../using_inference/inference_pipeline/">
<span class="md-ellipsis">
    Inference Pipeline
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="">
<span class="md-ellipsis">
    Active Learning
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
            Active Learning
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../enterprise/active-learning/active_learning/">
<span class="md-ellipsis">
    Use Active Learning
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../../../../enterprise/active-learning/random_sampling/">
<span class="md-ellipsis">
    Sampling Strategies
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
<span class="md-ellipsis">
    Enterprise Features
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_3">
<span class="md-nav__icon md-icon"></span>
            Enterprise Features
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../enterprise/parallel_processing/">
<span class="md-ellipsis">
    Parallel HTTP API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../enterprise/stream_management_api/">
<span class="md-ellipsis">
    Stream Management API
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
<span class="md-ellipsis">
    Inference Helpers
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_4">
<span class="md-nav__icon md-icon"></span>
            Inference Helpers
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../inference_helpers/inference_landing_page/">
<span class="md-ellipsis">
    Inference Landing Page
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../inference_helpers/inference_cli/">
<span class="md-ellipsis">
    Inference CLI
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../inference_helpers/inference_sdk/">
<span class="md-ellipsis">
    Inference SDK
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="">
<span class="md-ellipsis">
    inference configuration
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_5">
<span class="md-nav__icon md-icon"></span>
            inference configuration
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../server_configuration/environmental_variables/">
<span class="md-ellipsis">
    Environmental variables
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../server_configuration/accepted_input_formats/">
<span class="md-ellipsis">
    Security of input formats
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../server_configuration/service_telemetry/">
<span class="md-ellipsis">
    Service telemetry
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="">
<span class="md-ellipsis">
    Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_6">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1" id="__nav_3_6_1_label" tabindex="0">
<span class="md-ellipsis">
    Inference API Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_3_6_1">
<span class="md-nav__icon md-icon"></span>
            Inference API Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1_1" id="__nav_3_6_1_1_label" tabindex="0">
<span class="md-ellipsis">
    inference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_1_label" class="md-nav" data-md-level="4">
<label class="md-nav__title" for="__nav_3_6_1_1">
<span class="md-nav__icon md-icon"></span>
            inference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1_1_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1_1_1" id="__nav_3_6_1_1_1_label" tabindex="0">
<span class="md-ellipsis">
    core
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_1_1_label" class="md-nav" data-md-level="5">
<label class="md-nav__title" for="__nav_3_6_1_1_1">
<span class="md-nav__icon md-icon"></span>
            core
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../active_learning/accounting/">
<span class="md-ellipsis">
    active_learning
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../cache/base/">
<span class="md-ellipsis">
    cache
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../constants/">
<span class="md-ellipsis">
    constants
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../devices/utils/">
<span class="md-ellipsis">
    devices
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../entities/common/">
<span class="md-ellipsis">
    entities
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../env/">
<span class="md-ellipsis">
    env
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../exceptions/">
<span class="md-ellipsis">
    exceptions
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1_1_1_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1_1_1_8" id="__nav_3_6_1_1_1_8_label" tabindex="0">
<span class="md-ellipsis">
    interfaces
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_1_1_8_label" class="md-nav" data-md-level="6">
<label class="md-nav__title" for="__nav_3_6_1_1_1_8">
<span class="md-nav__icon md-icon"></span>
            interfaces
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../base/">
<span class="md-ellipsis">
    base
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../camera/camera/">
<span class="md-ellipsis">
    camera
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../http/handlers/workflows/">
<span class="md-ellipsis">
    http
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_6_1_1_1_8_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_6_1_1_1_8_4" id="__nav_3_6_1_1_1_8_4_label" tabindex="0">
<span class="md-ellipsis">
    stream
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_6_1_1_1_8_4_label" class="md-nav" data-md-level="7">
<label class="md-nav__title" for="__nav_3_6_1_1_1_8_4">
<span class="md-nav__icon md-icon"></span>
            stream
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../entities/">
<span class="md-ellipsis">
    entities
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    inference_pipeline
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    inference_pipeline
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline">
<span class="md-ellipsis">
      inference_pipeline
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline">
<span class="md-ellipsis">
      InferencePipeline
    </span>
</a>
<nav aria-label="InferencePipeline" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init">
<span class="md-ellipsis">
      init
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_custom_logic">
<span class="md-ellipsis">
      init_with_custom_logic
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_workflow">
<span class="md-ellipsis">
      init_with_workflow
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_yolo_world">
<span class="md-ellipsis">
      init_with_yolo_world
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../model_handlers/roboflow_models/">
<span class="md-ellipsis">
    model_handlers
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../sinks/">
<span class="md-ellipsis">
    sinks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../stream/">
<span class="md-ellipsis">
    stream
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../utils/">
<span class="md-ellipsis">
    utils
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../watchdog/">
<span class="md-ellipsis">
    watchdog
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../stream_manager/api/entities/">
<span class="md-ellipsis">
    stream_manager
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../udp/udp_stream/">
<span class="md-ellipsis">
    udp
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../logger/">
<span class="md-ellipsis">
    logger
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../managers/active_learning/">
<span class="md-ellipsis">
    managers
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../models/base/">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nms/">
<span class="md-ellipsis">
    nms
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../registries/base/">
<span class="md-ellipsis">
    registries
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../roboflow_api/">
<span class="md-ellipsis">
    roboflow_api
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../usage/">
<span class="md-ellipsis">
    usage
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../utils/async_utils/">
<span class="md-ellipsis">
    utils
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../version/">
<span class="md-ellipsis">
    version
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../warnings/">
<span class="md-ellipsis">
    warnings
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../workflows/core_steps/analytics/data_aggregator/v1/">
<span class="md-ellipsis">
    workflows
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../enterprise/parallel/dispatch_manager/">
<span class="md-ellipsis">
    enterprise
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../models/aliases/">
<span class="md-ellipsis">
    models
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../usage_tracking/collector/">
<span class="md-ellipsis">
    usage_tracking
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../quickstart/docker/">
<span class="md-ellipsis">
    Running With Docker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../quickstart/docker_configuration_options/">
<span class="md-ellipsis">
    Docker Configuration Options
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../quickstart/inference_gpu_windows/">
<span class="md-ellipsis">
    Install “bare metal” Inference GPU on Windows
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../contributing/">
<span class="md-ellipsis">
    Contribute to Inference
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="https://github.com/roboflow/inference/releases">
<span class="md-ellipsis">
    Changelog
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../../../../cookbooks/">
<span class="md-ellipsis">
    Cookbooks
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline">
<span class="md-ellipsis">
      inference_pipeline
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline">
<span class="md-ellipsis">
      InferencePipeline
    </span>
</a>
<nav aria-label="InferencePipeline" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init">
<span class="md-ellipsis">
      init
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_custom_logic">
<span class="md-ellipsis">
      init_with_custom_logic
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_workflow">
<span class="md-ellipsis">
      init_with_workflow
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_yolo_world">
<span class="md-ellipsis">
      init_with_yolo_world
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1>inference_pipeline</h1>
<div class="doc doc-object doc-module">
<a id="inference.core.interfaces.stream.inference_pipeline"></a>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" id="inference.core.interfaces.stream.inference_pipeline.InferencePipeline">
<code>InferencePipeline</code>
<a class="headerlink" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<details class="quote">
<summary>Source code in <code>inference/core/interfaces/stream/inference_pipeline.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span>
<span class="normal">975</span>
<span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span>
<span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span>
<span class="normal">982</span>
<span class="normal">983</span>
<span class="normal">984</span>
<span class="normal">985</span>
<span class="normal">986</span>
<span class="normal">987</span>
<span class="normal">988</span>
<span class="normal">989</span>
<span class="normal">990</span>
<span class="normal">991</span>
<span class="normal">992</span>
<span class="normal">993</span>
<span class="normal">994</span>
<span class="normal">995</span>
<span class="normal">996</span>
<span class="normal">997</span>
<span class="normal">998</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">InferencePipeline</span><span class="p">:</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">]],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">class_agnostic_nms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_candidates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_detections</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_decode_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"accurate"</span><span class="p">,</span>
        <span class="n">tradeoff_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">active_learning_enabled</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">active_learning_target_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sink_mode</span><span class="p">:</span> <span class="n">SinkMode</span> <span class="o">=</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        This class creates the abstraction for making inferences from Roboflow models against video stream.</span>
<span class="sd">        It allows to choose model from Roboflow platform and run predictions against</span>
<span class="sd">        video streams - just by the price of specifying which model to use and what to do with predictions.</span>

<span class="sd">        It allows to set the model post-processing parameters (via .init() or env) and intercept updates</span>
<span class="sd">        related to state of pipeline via `PipelineWatchDog` abstraction (although that is something probably</span>
<span class="sd">        useful only for advanced use-cases).</span>

<span class="sd">        For maximum efficiency, all separate chunks of processing: video decoding, inference, results dispatching</span>
<span class="sd">        are handled by separate threads.</span>

<span class="sd">        Given that reference to stream is passed and connectivity is lost - it attempts to re-connect with delay.</span>

<span class="sd">        Since version 0.9.11 it works not only for object detection models but is also compatible with stubs,</span>
<span class="sd">        classification, instance-segmentation and keypoint-detection models.</span>

<span class="sd">        Since version 0.9.18, `InferencePipeline` is capable of handling multiple video sources at once. If multiple</span>
<span class="sd">        sources are provided - source multiplexing will happen. One of the change introduced in that release is switch</span>
<span class="sd">        from `get_video_frames_generator(...)` as video frames provider into `multiplex_videos(...)`. For a single</span>
<span class="sd">        video source, the behaviour of `InferencePipeline` is remained unchanged when default parameters are used.</span>
<span class="sd">        For multiple videos - frames are multiplexed, and we can adjust the pipeline behaviour using new configuration</span>
<span class="sd">        options. `batch_collection_timeout` is one of the new option - it is the parameter of `multiplex_videos(...)`</span>
<span class="sd">        that dictates how long the batch frames collection process may wait for all sources to provide video frame.</span>
<span class="sd">        It can be set infinite (None) or with specific value representing fraction of second. We advise that value to</span>
<span class="sd">        be set in production solutions to avoid processing slow-down caused by source with unstable latency spikes.</span>
<span class="sd">        For more information on multiplexing process - please visit `multiplex_videos(...)` function docs.</span>
<span class="sd">        Another change is the way on how sinks work. They can work in `SinkMode.ADAPTIVE` - which means that</span>
<span class="sd">        video frames and predictions will be either provided to sink as list of objects, or specific elements -</span>
<span class="sd">        and the determining factor is number of sources (it will behave SEQUENTIAL for one source and BATCH if multiple</span>
<span class="sd">        ones are provided). All old sinks were adjusted to work in both modes, custom ones should be migrated</span>
<span class="sd">        to reflect changes in sink function signature.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_id (str): Name and version of model on the Roboflow platform (example: "my-model/3")</span>
<span class="sd">            video_reference (Union[str, int, List[Union[str, int]]]): Reference of source or sources to be used to make</span>
<span class="sd">                predictions against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">                (we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then</span>
<span class="sd">                it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">                `sink_mode` parameter comments.</span>
<span class="sd">            on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">                once prediction is ready - passing both decoded frame, their metadata and dict with standard</span>
<span class="sd">                Roboflow model prediction (different for specific types of models).</span>
<span class="sd">            api_key (Optional[str]): Roboflow API key - if not passed - will be looked in env under "ROBOFLOW_API_KEY"</span>
<span class="sd">                and "API_KEY" variables. API key, passed in some form is required.</span>
<span class="sd">            max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">                dictate max FPS of each video source.</span>
<span class="sd">                The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">                this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">                frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">                aligned with peoples expectations.</span>
<span class="sd">                New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">                `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">                be the default one end of Q4 2024!</span>
<span class="sd">            watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">                inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">            status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">                status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">                pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">                fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">                without re-raising. Default: None.</span>
<span class="sd">            source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            class_agnostic_nms (Optional[bool]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "CLASS_AGNOSTIC_NMS" with default "False"</span>
<span class="sd">            confidence (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "CONFIDENCE" with default "0.5"</span>
<span class="sd">            iou_threshold (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "IOU_THRESHOLD" with default "0.5"</span>
<span class="sd">            max_candidates (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "MAX_CANDIDATES" with default "3000"</span>
<span class="sd">            max_detections (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "MAX_DETECTIONS" with default "300"</span>
<span class="sd">            mask_decode_mode: (Optional[str]): Parameter of model post-processing. If not given - model "accurate" is</span>
<span class="sd">                used. Applicable for instance segmentation models</span>
<span class="sd">            tradeoff_factor (Optional[float]): Parameter of model post-processing. If not 0.0 - model default is used.</span>
<span class="sd">                Applicable for instance segmentation models</span>
<span class="sd">            active_learning_enabled (Optional[bool]): Flag to enable / disable Active Learning middleware (setting it</span>
<span class="sd">                true does not guarantee any data to be collected, as data collection is controlled by Roboflow backend -</span>
<span class="sd">                it just enables middleware intercepting predictions). If not given, env variable</span>
<span class="sd">                `ACTIVE_LEARNING_ENABLED` will be used. Please point out that Active Learning will be forcefully</span>
<span class="sd">                disabled in a scenario when Roboflow API key is not given, as Roboflow account is required</span>
<span class="sd">                for this feature to be operational.</span>
<span class="sd">            video_source_properties (Optional[Union[Dict[str, float], List[Optional[Dict[str, float]]]]]):</span>
<span class="sd">                Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties</span>
<span class="sd">                cv2.CAP_PROP_*. If not given, defaults for the video source will be used.</span>
<span class="sd">                It is optional and if provided can be provided as single dict (applicable for all sources) or</span>
<span class="sd">                as list of configs. Then the list must be of length of `video_reference` and may also contain None</span>
<span class="sd">                values to denote that specific source should remain not configured.</span>
<span class="sd">                Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">            active_learning_target_dataset (Optional[str]): Parameter to be used when Active Learning data registration</span>
<span class="sd">                should happen against different dataset than the one pointed by model_id</span>
<span class="sd">            batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">                to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">                frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">                unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">            sink_mode (SinkMode): Parameter that controls how video frames and predictions will be passed to sink</span>
<span class="sd">                handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,</span>
<span class="sd">                in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned</span>
<span class="sd">                in the order of video sources - with None values in the place of vide_frames / predictions that</span>
<span class="sd">                were skipped due to `batch_collection_timeout`.</span>
<span class="sd">                `SinkMode.ADAPTIVE` is a middle ground (and default mode) - all old sources will work in that mode</span>
<span class="sd">                against a single video input, as the pipeline will behave as if running in `SinkMode.SEQUENTIAL`.</span>
<span class="sd">                To handle multiple videos - sink needs to accept `predictions: List[Optional[dict]]` and</span>
<span class="sd">                `video_frame: List[Optional[VideoFrame]]`. It is also possible to process multiple videos using</span>
<span class="sd">                old sinks - but then `SinkMode.SEQUENTIAL` is to be used, causing sink to be called on each</span>
<span class="sd">                prediction element.</span>

<span class="sd">        Other ENV variables involved in low-level configuration:</span>
<span class="sd">        * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">        * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>
<span class="sd">        * ACTIVE_LEARNING_ENABLED - controls Active Learning middleware if explicit parameter not given</span>

<span class="sd">        Returns: Instance of InferencePipeline</span>

<span class="sd">        Throws:</span>
<span class="sd">            * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">                always if connection to stream is lost.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">api_key</span> <span class="o">=</span> <span class="n">API_KEY</span>
        <span class="n">inference_config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
            <span class="n">class_agnostic_nms</span><span class="o">=</span><span class="n">class_agnostic_nms</span><span class="p">,</span>
            <span class="n">confidence</span><span class="o">=</span><span class="n">confidence</span><span class="p">,</span>
            <span class="n">iou_threshold</span><span class="o">=</span><span class="n">iou_threshold</span><span class="p">,</span>
            <span class="n">max_candidates</span><span class="o">=</span><span class="n">max_candidates</span><span class="p">,</span>
            <span class="n">max_detections</span><span class="o">=</span><span class="n">max_detections</span><span class="p">,</span>
            <span class="n">mask_decode_mode</span><span class="o">=</span><span class="n">mask_decode_mode</span><span class="p">,</span>
            <span class="n">tradeoff_factor</span><span class="o">=</span><span class="n">tradeoff_factor</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">)</span>
        <span class="n">on_video_frame</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">default_process_frame</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">inference_config</span><span class="o">=</span><span class="n">inference_config</span>
        <span class="p">)</span>
        <span class="n">active_learning_middleware</span> <span class="o">=</span> <span class="n">NullActiveLearningMiddleware</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">active_learning_enabled</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"`active_learning_enabled` parameter not set - using env `ACTIVE_LEARNING_ENABLED` "</span>
                <span class="sa">f</span><span class="s2">"with value: </span><span class="si">{</span><span class="n">ACTIVE_LEARNING_ENABLED</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span>
            <span class="n">active_learning_enabled</span> <span class="o">=</span> <span class="n">ACTIVE_LEARNING_ENABLED</span>
        <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Roboflow API key not given - Active Learning is forced to be disabled."</span>
            <span class="p">)</span>
            <span class="n">active_learning_enabled</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">active_learning_enabled</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">resolved_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
            <span class="n">target_dataset</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">active_learning_target_dataset</span> <span class="ow">or</span> <span class="n">resolved_model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">active_learning_middleware</span> <span class="o">=</span> <span class="n">ThreadingActiveLearningMiddleware</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
                <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
                <span class="n">target_dataset</span><span class="o">=</span><span class="n">target_dataset</span><span class="p">,</span>
                <span class="n">model_id</span><span class="o">=</span><span class="n">resolved_model_id</span><span class="p">,</span>
                <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">al_sink</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">active_learning_sink</span><span class="p">,</span>
                <span class="n">active_learning_middleware</span><span class="o">=</span><span class="n">active_learning_middleware</span><span class="p">,</span>
                <span class="n">model_type</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">task_type</span><span class="p">,</span>
                <span class="n">disable_preproc_auto_orient</span><span class="o">=</span><span class="n">DISABLE_PREPROC_AUTO_ORIENT</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">"AL enabled - wrapping `on_prediction` with multi_sink() and active_learning_sink()"</span>
            <span class="p">)</span>
            <span class="n">on_prediction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">multi_sink</span><span class="p">,</span> <span class="n">sinks</span><span class="o">=</span><span class="p">[</span><span class="n">on_prediction</span><span class="p">,</span> <span class="n">al_sink</span><span class="p">])</span>
        <span class="n">on_pipeline_start</span> <span class="o">=</span> <span class="n">active_learning_middleware</span><span class="o">.</span><span class="n">start_registration_thread</span>
        <span class="n">on_pipeline_end</span> <span class="o">=</span> <span class="n">active_learning_middleware</span><span class="o">.</span><span class="n">stop_registration_thread</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">init_with_custom_logic</span><span class="p">(</span>
            <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
            <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
            <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
            <span class="n">on_pipeline_start</span><span class="o">=</span><span class="n">on_pipeline_start</span><span class="p">,</span>
            <span class="n">on_pipeline_end</span><span class="o">=</span><span class="n">on_pipeline_end</span><span class="p">,</span>
            <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
            <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
            <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
            <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
            <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
            <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
            <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
            <span class="n">sink_mode</span><span class="o">=</span><span class="n">sink_mode</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">init_with_yolo_world</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
        <span class="n">classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model_size</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"s"</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">class_agnostic_nms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_candidates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_detections</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sink_mode</span><span class="p">:</span> <span class="n">SinkMode</span> <span class="o">=</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        This class creates the abstraction for making inferences from YoloWorld against video stream.</span>
<span class="sd">        The way of how `InferencePipeline` works is displayed in `InferencePipeline.init(...)` initializer</span>
<span class="sd">        method.</span>

<span class="sd">        Args:</span>
<span class="sd">            video_reference (Union[str, int, List[Union[str, int]]]): Reference of source or sources to be used to make</span>
<span class="sd">                predictions against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">                (we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then</span>
<span class="sd">                it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">                `sink_mode` parameter comments.</span>
<span class="sd">            classes (List[str]): List of classes to execute zero-shot detection against</span>
<span class="sd">            model_size (str): version of model - to be chosen from `s`, `m`, `l`</span>
<span class="sd">            on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">                once prediction is ready - passing both decoded frame, their metadata and dict with standard</span>
<span class="sd">                Roboflow Object Detection prediction.</span>
<span class="sd">            max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">                dictate max FPS of each video source.</span>
<span class="sd">                The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">                this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">                frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">                aligned with peoples expectations.</span>
<span class="sd">                New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">                `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">                be the default one end of Q4 2024!</span>
<span class="sd">            watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">                inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">            status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">                status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">                pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">                fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">                without re-raising. Default: None.</span>
<span class="sd">            source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            class_agnostic_nms (Optional[bool]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "CLASS_AGNOSTIC_NMS" with default "False"</span>
<span class="sd">            confidence (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "CONFIDENCE" with default "0.5"</span>
<span class="sd">            iou_threshold (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "IOU_THRESHOLD" with default "0.5"</span>
<span class="sd">            max_candidates (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "MAX_CANDIDATES" with default "3000"</span>
<span class="sd">            max_detections (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">                env variable "MAX_DETECTIONS" with default "300"</span>
<span class="sd">            video_source_properties (Optional[Union[Dict[str, float], List[Optional[Dict[str, float]]]]]):</span>
<span class="sd">                Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties</span>
<span class="sd">                cv2.CAP_PROP_*. If not given, defaults for the video source will be used.</span>
<span class="sd">                It is optional and if provided can be provided as single dict (applicable for all sources) or</span>
<span class="sd">                as list of configs. Then the list must be of length of `video_reference` and may also contain None</span>
<span class="sd">                values to denote that specific source should remain not configured.</span>
<span class="sd">                Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">            batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">                to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">                frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">                unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">            sink_mode (SinkMode): Parameter that controls how video frames and predictions will be passed to sink</span>
<span class="sd">                handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,</span>
<span class="sd">                in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned</span>
<span class="sd">                in the order of video sources - with None values in the place of vide_frames / predictions that</span>
<span class="sd">                were skipped due to `batch_collection_timeout`.</span>
<span class="sd">                `SinkMode.ADAPTIVE` is a middle ground (and default mode) - all old sources will work in that mode</span>
<span class="sd">                against a single video input, as the pipeline will behave as if running in `SinkMode.SEQUENTIAL`.</span>
<span class="sd">                To handle multiple videos - sink needs to accept `predictions: List[Optional[dict]]` and</span>
<span class="sd">                `video_frame: List[Optional[VideoFrame]]`. It is also possible to process multiple videos using</span>
<span class="sd">                old sinks - but then `SinkMode.SEQUENTIAL` is to be used, causing sink to be called on each</span>
<span class="sd">                prediction element.</span>

<span class="sd">        Other ENV variables involved in low-level configuration:</span>
<span class="sd">        * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">        * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>

<span class="sd">        Returns: Instance of InferencePipeline</span>

<span class="sd">        Throws:</span>
<span class="sd">            * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">                always if connection to stream is lost.</span>
<span class="sd">        """</span>
        <span class="n">inference_config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
            <span class="n">class_agnostic_nms</span><span class="o">=</span><span class="n">class_agnostic_nms</span><span class="p">,</span>
            <span class="n">confidence</span><span class="o">=</span><span class="n">confidence</span><span class="p">,</span>
            <span class="n">iou_threshold</span><span class="o">=</span><span class="n">iou_threshold</span><span class="p">,</span>
            <span class="n">max_candidates</span><span class="o">=</span><span class="n">max_candidates</span><span class="p">,</span>
            <span class="n">max_detections</span><span class="o">=</span><span class="n">max_detections</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">inference.core.interfaces.stream.model_handlers.yolo_world</span> <span class="kn">import</span> <span class="p">(</span>
                <span class="n">build_yolo_world_inference_function</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">on_video_frame</span> <span class="o">=</span> <span class="n">build_yolo_world_inference_function</span><span class="p">(</span>
                <span class="n">model_id</span><span class="o">=</span><span class="sa">f</span><span class="s2">"yolo_world/</span><span class="si">{</span><span class="n">model_size</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
                <span class="n">inference_config</span><span class="o">=</span><span class="n">inference_config</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">CannotInitialiseModelError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Could not initialise yolo_world/</span><span class="si">{</span><span class="n">model_size</span><span class="si">}</span><span class="s2"> due to lack of sufficient dependencies. "</span>
                <span class="sa">f</span><span class="s2">"Use pip install inference[yolo-world] to install missing dependencies and try again."</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">error</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">init_with_custom_logic</span><span class="p">(</span>
            <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
            <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
            <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
            <span class="n">on_pipeline_start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">on_pipeline_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
            <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
            <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
            <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
            <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
            <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
            <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
            <span class="n">sink_mode</span><span class="o">=</span><span class="n">sink_mode</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="nd">@experimental</span><span class="p">(</span>
        <span class="n">reason</span><span class="o">=</span><span class="s2">"Usage of workflows with `InferencePipeline` is an experimental feature. Please report any issues "</span>
        <span class="s2">"here: https://github.com/roboflow/inference/issues"</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">init_with_workflow</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
        <span class="n">workflow_specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"image"</span><span class="p">,</span>
        <span class="n">workflows_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflow_init_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">workflows_thread_pool_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">video_metadata_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"video_metadata"</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">profiling_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"./inference_profiling"</span><span class="p">,</span>
        <span class="n">use_workflow_definition_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        This class creates the abstraction for making inferences from given workflow against video stream.</span>
<span class="sd">        The way of how `InferencePipeline` works is displayed in `InferencePipeline.init(...)` initializer</span>
<span class="sd">        method.</span>

<span class="sd">        Args:</span>
<span class="sd">            video_reference (Union[str, int, List[Union[str, int]]]): Reference of source to be used to make predictions</span>
<span class="sd">                against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">                (we handle whatever cv2 handles). It can also be a list of references (since v0.13.0) - and then</span>
<span class="sd">                it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">                `sink_mode` parameter comments.</span>
<span class="sd">            workflow_specification (Optional[dict]): Valid specification of workflow. See [workflow docs](https://github.com/roboflow/inference/tree/main/inference/enterprise/workflows).</span>
<span class="sd">                It can be provided optionally, but if not given, both `workspace_name` and `workflow_id`</span>
<span class="sd">                must be provided.</span>
<span class="sd">            workspace_name (Optional[str]): When using registered workflows - Roboflow workspace name needs to be given.</span>
<span class="sd">            workflow_id (Optional[str]): When using registered workflows - Roboflow workflow id needs to be given.</span>
<span class="sd">            api_key (Optional[str]): Roboflow API key - if not passed - will be looked in env under "ROBOFLOW_API_KEY"</span>
<span class="sd">                and "API_KEY" variables. API key, passed in some form is required.</span>
<span class="sd">            image_input_name (str): Name of input image defined in `workflow_specification` or Workflow definition saved</span>
<span class="sd">                on the Roboflow Platform. `InferencePipeline` will be injecting video frames to workflow through that</span>
<span class="sd">                parameter name.</span>
<span class="sd">            workflows_parameters (Optional[Dict[str, Any]]): Dictionary with additional parameters that can be</span>
<span class="sd">                defined within `workflow_specification`.</span>
<span class="sd">            on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">                once prediction is ready - passing both decoded frame, their metadata and dict with workflow output.</span>
<span class="sd">            max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">                dictate max FPS of each video source.</span>
<span class="sd">                The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">                this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">                frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">                aligned with peoples expectations.</span>
<span class="sd">                New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">                `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">                be the default one end of Q4 2024!</span>
<span class="sd">            watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">                inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">            status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">                status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">                pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">                fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">                without re-raising. Default: None.</span>
<span class="sd">            source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            video_source_properties (Optional[dict[str, float]]): Optional source properties to set up the video source,</span>
<span class="sd">                corresponding to cv2 VideoCapture properties cv2.CAP_PROP_*. If not given, defaults for the video source</span>
<span class="sd">                will be used.</span>
<span class="sd">                Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">            workflow_init_parameters (Optional[Dict[str, Any]]): Additional init parameters to be used by</span>
<span class="sd">                workflows Execution Engine to init steps of your workflow - may be required when running workflows</span>
<span class="sd">                with custom plugins.</span>
<span class="sd">            workflows_thread_pool_workers (int): Number of workers for workflows thread pool which is used</span>
<span class="sd">                by workflows blocks to run background tasks.</span>
<span class="sd">            cancel_thread_pool_tasks_on_exit (bool): Flag to decide if unstated background tasks should be</span>
<span class="sd">                canceled at the end of InferencePipeline processing. By default, when video file ends or</span>
<span class="sd">                pipeline is stopped, tasks that has not started will be cancelled.</span>
<span class="sd">            video_metadata_input_name (str): Name of input for video metadata defined in `workflow_specification` or</span>
<span class="sd">                Workflow definition saved  on the Roboflow Platform. `InferencePipeline` will be injecting video frames</span>
<span class="sd">                metadata to workflows through that parameter name.</span>
<span class="sd">            batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">                to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">                frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">                unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">            profiling_directory (str): Directory where workflows profiler traces will be dumped. To enable profiling</span>
<span class="sd">                export `ENABLE_WORKFLOWS_PROFILING=True` environmental variable. You may specify number of workflow</span>
<span class="sd">                runs in a buffer with environmental variable `WORKFLOWS_PROFILER_BUFFER_SIZE=n` - making last `n`</span>
<span class="sd">                frames to be present in buffer on processing end.</span>
<span class="sd">            use_workflow_definition_cache (bool): Controls usage of cache for workflow definitions. Set this to False</span>
<span class="sd">                when you frequently modify definition saved in Roboflow app and want to fetch the</span>
<span class="sd">                newest version for the request. Only applies for Workflows definitions saved on Roboflow platform.</span>

<span class="sd">        Other ENV variables involved in low-level configuration:</span>
<span class="sd">        * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">        * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>

<span class="sd">        Returns: Instance of InferencePipeline</span>

<span class="sd">        Throws:</span>
<span class="sd">            * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">                always if connection to stream is lost.</span>
<span class="sd">            * ValueError if workflow specification not provided and registered workflow not pointed out</span>
<span class="sd">            * NotImplementedError if workflow used against multiple videos which is not supported yet</span>
<span class="sd">            * MissingApiKeyError - if API key is not provided in situation when retrieving workflow definition</span>
<span class="sd">                from Roboflow API is needed</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">ENABLE_WORKFLOWS_PROFILING</span><span class="p">:</span>
            <span class="n">profiler</span> <span class="o">=</span> <span class="n">BaseWorkflowsProfiler</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
                <span class="n">max_runs_in_buffer</span><span class="o">=</span><span class="n">WORKFLOWS_PROFILER_BUFFER_SIZE</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">profiler</span> <span class="o">=</span> <span class="n">NullWorkflowsProfiler</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">api_key</span> <span class="o">=</span> <span class="n">API_KEY</span>
        <span class="n">named_workflow_specified</span> <span class="o">=</span> <span class="p">(</span><span class="n">workspace_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="n">workflow_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">named_workflow_specified</span> <span class="o">!=</span> <span class="p">(</span><span class="n">workflow_specification</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Parameters (`workspace_name`, `workflow_id`) can be used mutually exclusive with "</span>
                <span class="s2">"`workflow_specification`, but at least one must be set."</span>
            <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">inference.core.interfaces.stream.model_handlers.workflows</span> <span class="kn">import</span> <span class="p">(</span>
                <span class="n">WorkflowRunner</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="kn">from</span> <span class="nn">inference.core.roboflow_api</span> <span class="kn">import</span> <span class="n">get_workflow_specification</span>
            <span class="kn">from</span> <span class="nn">inference.core.workflows.execution_engine.core</span> <span class="kn">import</span> <span class="n">ExecutionEngine</span>

            <span class="k">if</span> <span class="n">workflow_specification</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">MissingApiKeyError</span><span class="p">(</span>
                        <span class="s2">"Roboflow API key needs to be provided either as parameter or via env variable "</span>
                        <span class="s2">"ROBOFLOW_API_KEY. If you do not know how to get API key - visit "</span>
                        <span class="s2">"https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key to learn how to "</span>
                        <span class="s2">"retrieve one."</span>
                    <span class="p">)</span>
                <span class="k">with</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile_execution_phase</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">"workflow_definition_fetching"</span><span class="p">,</span>
                    <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="s2">"inference_package_operation"</span><span class="p">],</span>
                <span class="p">):</span>
                    <span class="n">workflow_specification</span> <span class="o">=</span> <span class="n">get_workflow_specification</span><span class="p">(</span>
                        <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
                        <span class="n">workspace_id</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
                        <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_id</span><span class="p">,</span>
                        <span class="n">use_cache</span><span class="o">=</span><span class="n">use_workflow_definition_cache</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="n">model_registry</span> <span class="o">=</span> <span class="n">RoboflowModelRegistry</span><span class="p">(</span><span class="n">ROBOFLOW_MODEL_TYPES</span><span class="p">)</span>
            <span class="n">model_manager</span> <span class="o">=</span> <span class="n">BackgroundTaskActiveLearningManager</span><span class="p">(</span>
                <span class="n">model_registry</span><span class="o">=</span><span class="n">model_registry</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span>
            <span class="p">)</span>
            <span class="n">model_manager</span> <span class="o">=</span> <span class="n">WithFixedSizeCache</span><span class="p">(</span>
                <span class="n">model_manager</span><span class="p">,</span>
                <span class="n">max_size</span><span class="o">=</span><span class="n">MAX_ACTIVE_MODELS</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">api_key</span> <span class="o">=</span> <span class="n">API_KEY</span>
            <span class="k">if</span> <span class="n">workflow_init_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">workflow_init_parameters</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">thread_pool_executor</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span>
                <span class="n">max_workers</span><span class="o">=</span><span class="n">workflows_thread_pool_workers</span>
            <span class="p">)</span>
            <span class="n">workflow_init_parameters</span><span class="p">[</span><span class="s2">"workflows_core.model_manager"</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_manager</span>
            <span class="n">workflow_init_parameters</span><span class="p">[</span><span class="s2">"workflows_core.api_key"</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_key</span>
            <span class="n">workflow_init_parameters</span><span class="p">[</span><span class="s2">"workflows_core.thread_pool_executor"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">thread_pool_executor</span>
            <span class="p">)</span>
            <span class="n">execution_engine</span> <span class="o">=</span> <span class="n">ExecutionEngine</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
                <span class="n">workflow_definition</span><span class="o">=</span><span class="n">workflow_specification</span><span class="p">,</span>
                <span class="n">init_parameters</span><span class="o">=</span><span class="n">workflow_init_parameters</span><span class="p">,</span>
                <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_id</span><span class="p">,</span>
                <span class="n">profiler</span><span class="o">=</span><span class="n">profiler</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">workflow_runner</span> <span class="o">=</span> <span class="n">WorkflowRunner</span><span class="p">()</span>
            <span class="n">on_video_frame</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">workflow_runner</span><span class="o">.</span><span class="n">run_workflow</span><span class="p">,</span>
                <span class="n">workflows_parameters</span><span class="o">=</span><span class="n">workflows_parameters</span><span class="p">,</span>
                <span class="n">execution_engine</span><span class="o">=</span><span class="n">execution_engine</span><span class="p">,</span>
                <span class="n">image_input_name</span><span class="o">=</span><span class="n">image_input_name</span><span class="p">,</span>
                <span class="n">video_metadata_input_name</span><span class="o">=</span><span class="n">video_metadata_input_name</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">CannotInitialiseModelError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Could not initialise workflow processing due to lack of dependencies required. "</span>
                <span class="sa">f</span><span class="s2">"Please provide an issue report under https://github.com/roboflow/inference/issues"</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">error</span>
        <span class="n">on_pipeline_end_closure</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">on_pipeline_end</span><span class="p">,</span>
            <span class="n">thread_pool_executor</span><span class="o">=</span><span class="n">thread_pool_executor</span><span class="p">,</span>
            <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="o">=</span><span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">,</span>
            <span class="n">profiler</span><span class="o">=</span><span class="n">profiler</span><span class="p">,</span>
            <span class="n">profiling_directory</span><span class="o">=</span><span class="n">profiling_directory</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">init_with_custom_logic</span><span class="p">(</span>
            <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
            <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
            <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
            <span class="n">on_pipeline_start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">on_pipeline_end</span><span class="o">=</span><span class="n">on_pipeline_end_closure</span><span class="p">,</span>
            <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
            <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
            <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
            <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
            <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
            <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
            <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">init_with_custom_logic</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">]],</span>
        <span class="n">on_video_frame</span><span class="p">:</span> <span class="n">InferenceHandler</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">on_pipeline_start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">on_pipeline_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sink_mode</span><span class="p">:</span> <span class="n">SinkMode</span> <span class="o">=</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        This class creates the abstraction for making inferences from given workflow against video stream.</span>
<span class="sd">        The way of how `InferencePipeline` works is displayed in `InferencePipeline.init(...)` initialiser</span>
<span class="sd">        method.</span>

<span class="sd">        Args:</span>
<span class="sd">            video_reference (Union[str, int, List[Union[str, int]]]): Reference of source or sources to be used to make</span>
<span class="sd">                predictions against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">                (we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then</span>
<span class="sd">                it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">                `sink_mode` parameter comments.</span>
<span class="sd">            on_video_frame (Callable[[VideoFrame], AnyPrediction]): function supposed to make prediction (or do another</span>
<span class="sd">                kind of custom processing according to your will). Accept `VideoFrame` object and is supposed</span>
<span class="sd">                to return dictionary with results of any kind.</span>
<span class="sd">            on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">                once prediction is ready - passing both decoded frame, their metadata and dict with output from your</span>
<span class="sd">                custom callable `on_video_frame(...)`. Logic here must be adjusted to the output of `on_video_frame`.</span>
<span class="sd">            on_pipeline_start (Optional[Callable[[], None]]): Optional (parameter-free) function to be called</span>
<span class="sd">                whenever pipeline starts</span>
<span class="sd">            on_pipeline_end (Optional[Callable[[], None]]): Optional (parameter-free) function to be called</span>
<span class="sd">                whenever pipeline ends</span>
<span class="sd">            max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">                dictate max FPS of each video source.</span>
<span class="sd">                The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">                this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">                frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">                aligned with peoples expectations.</span>
<span class="sd">                New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">                `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">                be the default one end of Q4 2024!</span>
<span class="sd">            watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">                inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">            status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">                status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">                pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">                fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">                without re-raising. Default: None.</span>
<span class="sd">            source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">                video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">                Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">            video_source_properties (Optional[Union[Dict[str, float], List[Optional[Dict[str, float]]]]]):</span>
<span class="sd">                Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties</span>
<span class="sd">                cv2.CAP_PROP_*. If not given, defaults for the video source will be used.</span>
<span class="sd">                It is optional and if provided can be provided as single dict (applicable for all sources) or</span>
<span class="sd">                as list of configs. Then the list must be of length of `video_reference` and may also contain None</span>
<span class="sd">                values to denote that specific source should remain not configured.</span>
<span class="sd">                Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">            batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">                to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">                frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">                unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">            sink_mode (SinkMode): Parameter that controls how video frames and predictions will be passed to sink</span>
<span class="sd">                handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,</span>
<span class="sd">                in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned</span>
<span class="sd">                in the order of video sources - with None values in the place of vide_frames / predictions that</span>
<span class="sd">                were skipped due to `batch_collection_timeout`.</span>
<span class="sd">                `SinkMode.ADAPTIVE` is a middle ground (and default mode) - all old sources will work in that mode</span>
<span class="sd">                against a single video input, as the pipeline will behave as if running in `SinkMode.SEQUENTIAL`.</span>
<span class="sd">                To handle multiple videos - sink needs to accept `predictions: List[Optional[dict]]` and</span>
<span class="sd">                `video_frame: List[Optional[VideoFrame]]`. It is also possible to process multiple videos using</span>
<span class="sd">                old sinks - but then `SinkMode.SEQUENTIAL` is to be used, causing sink to be called on each</span>
<span class="sd">                prediction element.</span>

<span class="sd">        Other ENV variables involved in low-level configuration:</span>
<span class="sd">        * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">        * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>

<span class="sd">        Returns: Instance of InferencePipeline</span>

<span class="sd">        Throws:</span>
<span class="sd">            * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">                always if connection to stream is lost.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">watchdog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">watchdog</span> <span class="o">=</span> <span class="n">NullPipelineWatchdog</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">status_update_handlers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">status_update_handlers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">status_update_handlers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">watchdog</span><span class="o">.</span><span class="n">on_status_update</span><span class="p">)</span>
        <span class="n">desired_source_fps</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING</span><span class="p">:</span>
            <span class="n">desired_source_fps</span> <span class="o">=</span> <span class="n">max_fps</span>
        <span class="n">video_sources</span> <span class="o">=</span> <span class="n">prepare_video_sources</span><span class="p">(</span>
            <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
            <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
            <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
            <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
            <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
            <span class="n">desired_source_fps</span><span class="o">=</span><span class="n">desired_source_fps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">watchdog</span><span class="o">.</span><span class="n">register_video_sources</span><span class="p">(</span><span class="n">video_sources</span><span class="o">=</span><span class="n">video_sources</span><span class="p">)</span>
        <span class="n">predictions_queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">PREDICTIONS_QUEUE_SIZE</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
            <span class="n">video_sources</span><span class="o">=</span><span class="n">video_sources</span><span class="p">,</span>
            <span class="n">predictions_queue</span><span class="o">=</span><span class="n">predictions_queue</span><span class="p">,</span>
            <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
            <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
            <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
            <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
            <span class="n">on_pipeline_start</span><span class="o">=</span><span class="n">on_pipeline_start</span><span class="p">,</span>
            <span class="n">on_pipeline_end</span><span class="o">=</span><span class="n">on_pipeline_end</span><span class="p">,</span>
            <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
            <span class="n">sink_mode</span><span class="o">=</span><span class="n">sink_mode</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">on_video_frame</span><span class="p">:</span> <span class="n">InferenceHandler</span><span class="p">,</span>
        <span class="n">video_sources</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoSource</span><span class="p">],</span>
        <span class="n">predictions_queue</span><span class="p">:</span> <span class="n">Queue</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="p">:</span> <span class="n">PipelineWatchDog</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]],</span>
        <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">on_pipeline_start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">on_pipeline_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sink_mode</span><span class="p">:</span> <span class="n">SinkMode</span> <span class="o">=</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_on_video_frame</span> <span class="o">=</span> <span class="n">on_video_frame</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span> <span class="o">=</span> <span class="n">video_sources</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_on_prediction</span> <span class="o">=</span> <span class="n">on_prediction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_fps</span> <span class="o">=</span> <span class="n">max_fps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_predictions_queue</span> <span class="o">=</span> <span class="n">predictions_queue</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_watchdog</span> <span class="o">=</span> <span class="n">watchdog</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_command_handler_thread</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Thread</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inference_thread</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Thread</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dispatching_thread</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Thread</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_camera_restart_ongoing</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_status_update_handlers</span> <span class="o">=</span> <span class="n">status_update_handlers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_on_pipeline_start</span> <span class="o">=</span> <span class="n">on_pipeline_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_on_pipeline_end</span> <span class="o">=</span> <span class="n">on_pipeline_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_collection_timeout</span> <span class="o">=</span> <span class="n">batch_collection_timeout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sink_mode</span> <span class="o">=</span> <span class="n">sink_mode</span>

    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_main_thread</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stop</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inference_thread</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_execute_inference</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inference_thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_on_pipeline_start</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_on_pipeline_start</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_main_thread</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dispatch_inference_results</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dispatching_thread</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dispatch_inference_results</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dispatching_thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">terminate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stop</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">video_source</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span><span class="p">:</span>
            <span class="n">video_source</span><span class="o">.</span><span class="n">terminate</span><span class="p">(</span>
                <span class="n">wait_on_frames_consumption</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">purge_frames_buffer</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">pause_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">video_source</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">video_source</span><span class="o">.</span><span class="n">source_id</span> <span class="o">==</span> <span class="n">source_id</span> <span class="ow">or</span> <span class="n">source_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">video_source</span><span class="o">.</span><span class="n">pause</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">mute_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">video_source</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">video_source</span><span class="o">.</span><span class="n">source_id</span> <span class="o">==</span> <span class="n">source_id</span> <span class="ow">or</span> <span class="n">source_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">video_source</span><span class="o">.</span><span class="n">mute</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">resume_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">video_source</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">video_source</span><span class="o">.</span><span class="n">source_id</span> <span class="o">==</span> <span class="n">source_id</span> <span class="ow">or</span> <span class="n">source_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">video_source</span><span class="o">.</span><span class="n">resume</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">join</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_thread</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inference_thread</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_inference_thread</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dispatching_thread</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dispatching_thread</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dispatching_thread</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_on_pipeline_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_on_pipeline_end</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_execute_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">send_inference_pipeline_status_update</span><span class="p">(</span>
            <span class="n">severity</span><span class="o">=</span><span class="n">UpdateSeverity</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
            <span class="n">event_type</span><span class="o">=</span><span class="n">INFERENCE_THREAD_STARTED_EVENT</span><span class="p">,</span>
            <span class="n">status_update_handlers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_status_update_handlers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Inference thread started"</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">video_frames</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_frames</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_watchdog</span><span class="o">.</span><span class="n">on_model_inference_started</span><span class="p">(</span>
                    <span class="n">frames</span><span class="o">=</span><span class="n">video_frames</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_on_video_frame</span><span class="p">(</span><span class="n">video_frames</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_watchdog</span><span class="o">.</span><span class="n">on_model_prediction_ready</span><span class="p">(</span>
                    <span class="n">frames</span><span class="o">=</span><span class="n">video_frames</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_predictions_queue</span><span class="o">.</span><span class="n">put</span><span class="p">((</span><span class="n">predictions</span><span class="p">,</span> <span class="n">video_frames</span><span class="p">))</span>
                <span class="n">send_inference_pipeline_status_update</span><span class="p">(</span>
                    <span class="n">severity</span><span class="o">=</span><span class="n">UpdateSeverity</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span>
                    <span class="n">event_type</span><span class="o">=</span><span class="n">INFERENCE_COMPLETED_EVENT</span><span class="p">,</span>
                    <span class="n">payload</span><span class="o">=</span><span class="p">{</span>
                        <span class="s2">"frames_ids"</span><span class="p">:</span> <span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">frame_id</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">video_frames</span><span class="p">],</span>
                        <span class="s2">"frames_timestamps"</span><span class="p">:</span> <span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">frame_timestamp</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">video_frames</span><span class="p">],</span>
                        <span class="s2">"sources_id"</span><span class="p">:</span> <span class="p">[</span><span class="n">f</span><span class="o">.</span><span class="n">source_id</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">video_frames</span><span class="p">],</span>
                    <span class="p">},</span>
                    <span class="n">status_update_handlers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_status_update_handlers</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">"error_type"</span><span class="p">:</span> <span class="n">error</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="s2">"error_message"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">),</span>
                <span class="s2">"error_context"</span><span class="p">:</span> <span class="s2">"inference_thread"</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">send_inference_pipeline_status_update</span><span class="p">(</span>
                <span class="n">severity</span><span class="o">=</span><span class="n">UpdateSeverity</span><span class="o">.</span><span class="n">ERROR</span><span class="p">,</span>
                <span class="n">event_type</span><span class="o">=</span><span class="n">INFERENCE_ERROR_EVENT</span><span class="p">,</span>
                <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
                <span class="n">status_update_handlers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_status_update_handlers</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Encountered inference error: </span><span class="si">{</span><span class="n">error</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_predictions_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">send_inference_pipeline_status_update</span><span class="p">(</span>
                <span class="n">severity</span><span class="o">=</span><span class="n">UpdateSeverity</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
                <span class="n">event_type</span><span class="o">=</span><span class="n">INFERENCE_THREAD_FINISHED_EVENT</span><span class="p">,</span>
                <span class="n">status_update_handlers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_status_update_handlers</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Inference thread finished"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_dispatch_inference_results</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">inference_results</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
                <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">AnyPrediction</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoFrame</span><span class="p">]]</span>
            <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predictions_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">inference_results</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_predictions_queue</span><span class="o">.</span><span class="n">task_done</span><span class="p">()</span>
                <span class="k">break</span>
            <span class="n">predictions</span><span class="p">,</span> <span class="n">video_frames</span> <span class="o">=</span> <span class="n">inference_results</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_on_prediction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_handle_predictions_dispatching</span><span class="p">(</span>
                    <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span>
                    <span class="n">video_frames</span><span class="o">=</span><span class="n">video_frames</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_predictions_queue</span><span class="o">.</span><span class="n">task_done</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_handle_predictions_dispatching</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">predictions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">AnyPrediction</span><span class="p">],</span>
        <span class="n">video_frames</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoFrame</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_use_batch_sink</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_use_batch_sink</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">video_frames</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">frame_predictions</span><span class="p">,</span> <span class="n">video_frame</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">video_frames</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_use_sink</span><span class="p">(</span><span class="n">frame_predictions</span><span class="p">,</span> <span class="n">video_frame</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_should_use_batch_sink</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sink_mode</span> <span class="ow">is</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">BATCH</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sink_mode</span> <span class="ow">is</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_use_batch_sink</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">predictions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">AnyPrediction</span><span class="p">],</span>
        <span class="n">video_frames</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoFrame</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># This function makes it possible to always call sinks with payloads aligned to order of</span>
        <span class="c1"># video sources - marking empty frames as None</span>
        <span class="n">results_by_source_id</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">video_frame</span><span class="o">.</span><span class="n">source_id</span><span class="p">:</span> <span class="p">(</span><span class="n">frame_predictions</span><span class="p">,</span> <span class="n">video_frame</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">frame_predictions</span><span class="p">,</span> <span class="n">video_frame</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">video_frames</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">source_id_aligned_sink_payload</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">results_by_source_id</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">video_source</span><span class="o">.</span><span class="n">source_id</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">video_source</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span>
        <span class="p">]</span>
        <span class="n">source_id_aligned_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">source_id_aligned_sink_payload</span><span class="p">]</span>
        <span class="n">source_id_aligned_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">source_id_aligned_sink_payload</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_sink</span><span class="p">(</span>
            <span class="n">predictions</span><span class="o">=</span><span class="n">source_id_aligned_predictions</span><span class="p">,</span>
            <span class="n">video_frames</span><span class="o">=</span><span class="n">source_id_aligned_frames</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_use_sink</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">predictions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">AnyPrediction</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">AnyPrediction</span><span class="p">]]],</span>
        <span class="n">video_frames</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">VideoFrame</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">VideoFrame</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_on_prediction</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">video_frames</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">"error_type"</span><span class="p">:</span> <span class="n">error</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="s2">"error_message"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">error</span><span class="p">),</span>
                <span class="s2">"error_context"</span><span class="p">:</span> <span class="s2">"inference_results_dispatching"</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">send_inference_pipeline_status_update</span><span class="p">(</span>
                <span class="n">severity</span><span class="o">=</span><span class="n">UpdateSeverity</span><span class="o">.</span><span class="n">ERROR</span><span class="p">,</span>
                <span class="n">event_type</span><span class="o">=</span><span class="n">INFERENCE_RESULTS_DISPATCHING_ERROR_EVENT</span><span class="p">,</span>
                <span class="n">payload</span><span class="o">=</span><span class="n">payload</span><span class="p">,</span>
                <span class="n">status_update_handlers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_status_update_handlers</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error in results dispatching - </span><span class="si">{</span><span class="n">error</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_generate_frames</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">VideoFrame</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">video_source</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span><span class="p">:</span>
            <span class="n">video_source</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="n">max_fps</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING</span><span class="p">:</span>
            <span class="n">max_fps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_fps</span>
        <span class="k">yield from</span> <span class="n">multiplex_videos</span><span class="p">(</span>
            <span class="n">videos</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_video_sources</span><span class="p">,</span>
            <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
            <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_collection_timeout</span><span class="p">,</span>
            <span class="n">should_stop</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init">
<code class="highlight language-python"><span class="n">init</span><span class="p">(</span><span class="n">video_reference</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">on_prediction</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_fps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">watchdog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">status_update_handlers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_agnostic_nms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">iou_threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_candidates</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_detections</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask_decode_mode</span><span class="o">=</span><span class="s1">'accurate'</span><span class="p">,</span> <span class="n">tradeoff_factor</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">active_learning_enabled</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">video_source_properties</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">active_learning_target_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sink_mode</span><span class="o">=</span><span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">)</span></code>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
</span>
<a class="headerlink" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>This class creates the abstraction for making inferences from Roboflow models against video stream.
It allows to choose model from Roboflow platform and run predictions against
video streams - just by the price of specifying which model to use and what to do with predictions.</p>
<p>It allows to set the model post-processing parameters (via .init() or env) and intercept updates
related to state of pipeline via <code>PipelineWatchDog</code> abstraction (although that is something probably
useful only for advanced use-cases).</p>
<p>For maximum efficiency, all separate chunks of processing: video decoding, inference, results dispatching
are handled by separate threads.</p>
<p>Given that reference to stream is passed and connectivity is lost - it attempts to re-connect with delay.</p>
<p>Since version 0.9.11 it works not only for object detection models but is also compatible with stubs,
classification, instance-segmentation and keypoint-detection models.</p>
<p>Since version 0.9.18, <code>InferencePipeline</code> is capable of handling multiple video sources at once. If multiple
sources are provided - source multiplexing will happen. One of the change introduced in that release is switch
from <code>get_video_frames_generator(...)</code> as video frames provider into <code>multiplex_videos(...)</code>. For a single
video source, the behaviour of <code>InferencePipeline</code> is remained unchanged when default parameters are used.
For multiple videos - frames are multiplexed, and we can adjust the pipeline behaviour using new configuration
options. <code>batch_collection_timeout</code> is one of the new option - it is the parameter of <code>multiplex_videos(...)</code>
that dictates how long the batch frames collection process may wait for all sources to provide video frame.
It can be set infinite (None) or with specific value representing fraction of second. We advise that value to
be set in production solutions to avoid processing slow-down caused by source with unstable latency spikes.
For more information on multiplexing process - please visit <code>multiplex_videos(...)</code> function docs.
Another change is the way on how sinks work. They can work in <code>SinkMode.ADAPTIVE</code> - which means that
video frames and predictions will be either provided to sink as list of objects, or specific elements -
and the determining factor is number of sources (it will behave SEQUENTIAL for one source and BATCH if multiple
ones are provided). All old sinks were adjusted to work in both modes, custom ones should be migrated
to reflect changes in sink function signature.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>model_id</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>Name and version of model on the Roboflow platform (example: "my-model/3")</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>video_reference</code>
</td>
<td>
<code><span title="typing.Union">Union</span>[str, int, <span title="typing.List">List</span>[<span title="typing.Union">Union</span>[str, int]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Reference of source or sources to be used to make
predictions against. It can be video file path, stream URL and device (like camera) id
(we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then
it will trigger parallel processing of multiple sources. It has some implication on sinks. See:
<code>sink_mode</code> parameter comments.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>on_prediction</code>
</td>
<td>
<code>Callable[AnyPrediction, VideoFrame], None]</code>
</td>
<td>
<div class="doc-md-description">
<p>Function to be called
once prediction is ready - passing both decoded frame, their metadata and dict with standard
Roboflow model prediction (different for specific types of models).</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>api_key</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>Roboflow API key - if not passed - will be looked in env under "ROBOFLOW_API_KEY"
and "API_KEY" variables. API key, passed in some form is required.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_fps</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, int]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Specific value passed as this parameter will be used to
dictate max FPS of each video source.
The implementation details of this option has been changed in release <code>v0.26.0</code>. Prior to the release
this value, when applied to video files caused the processing to wait <code>1 / max_fps</code> seconds before next
frame is processed - the new implementation drops the intermediate frames, which seems to be more
aligned with peoples expectations.
New behaviour is now enabled in experimental mode, by setting environmental variable flag
<code>ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True</code>. Please note that the new behaviour will
be the default one end of Q4 2024!</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>watchdog</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.stream.watchdog.PipelineWatchDog">PipelineWatchDog</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Implementation of class that allows profiling of
inference pipeline - if not given null implementation (doing nothing) will be used.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>status_update_handlers</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="typing.Callable">Callable</span>[[<a class="autorefs autorefs-internal" title="inference.core.interfaces.camera.entities.StatusUpdate" href="../../camera/entities/#inference.core.interfaces.camera.entities.StatusUpdate">StatusUpdate</a>], None]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of handlers to intercept
status updates of all elements of the pipeline. Should be used only if detailed inspection of
pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed
fast - otherwise they will impair pipeline performance. All errors will be logged as warnings
without re-raising. Default: None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_filling_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferFillingStrategy">BufferFillingStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream decoding behaviour. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_consumption_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferConsumptionStrategy">BufferConsumptionStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream frames consumption. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>class_agnostic_nms</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[bool]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "CLASS_AGNOSTIC_NMS" with default "False"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>confidence</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "CONFIDENCE" with default "0.5"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>iou_threshold</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "IOU_THRESHOLD" with default "0.5"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_candidates</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[int]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "MAX_CANDIDATES" with default "3000"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_detections</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[int]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "MAX_DETECTIONS" with default "300"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>mask_decode_mode</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>(Optional[str]): Parameter of model post-processing. If not given - model "accurate" is
used. Applicable for instance segmentation models</p>
</div>
</td>
<td>
<code>'accurate'</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>tradeoff_factor</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not 0.0 - model default is used.
Applicable for instance segmentation models</p>
</div>
</td>
<td>
<code>0.0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>active_learning_enabled</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[bool]</code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to enable / disable Active Learning middleware (setting it
true does not guarantee any data to be collected, as data collection is controlled by Roboflow backend -
it just enables middleware intercepting predictions). If not given, env variable
<code>ACTIVE_LEARNING_ENABLED</code> will be used. Please point out that Active Learning will be forcefully
disabled in a scenario when Roboflow API key is not given, as Roboflow account is required
for this feature to be operational.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>video_source_properties</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="typing.Dict">Dict</span>[str, float], <span title="typing.List">List</span>[<span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, float]]]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties
cv2.CAP_PROP_*. If not given, defaults for the video source will be used.
It is optional and if provided can be provided as single dict (applicable for all sources) or
as list of configs. Then the list must be of length of <code>video_reference</code> and may also contain None
values to denote that specific source should remain not configured.
Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>active_learning_target_dataset</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter to be used when Active Learning data registration
should happen against different dataset than the one pointed by model_id</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>batch_collection_timeout</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of multiplex_videos(...) dictating how long process
to grab frames from multiple sources can wait for batch to be filled before yielding already collected
frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows
unstable latency. Visit <code>multiplex_videos(...)</code> for more information about multiplexing process.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>sink_mode</code>
</td>
<td>
<code><span title="inference.core.interfaces.stream.inference_pipeline.SinkMode">SinkMode</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter that controls how video frames and predictions will be passed to sink
handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,
in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned
in the order of video sources - with None values in the place of vide_frames / predictions that
were skipped due to <code>batch_collection_timeout</code>.
<code>SinkMode.ADAPTIVE</code> is a middle ground (and default mode) - all old sources will work in that mode
against a single video input, as the pipeline will behave as if running in <code>SinkMode.SEQUENTIAL</code>.
To handle multiple videos - sink needs to accept <code>predictions: List[Optional[dict]]</code> and
<code>video_frame: List[Optional[VideoFrame]]</code>. It is also possible to process multiple videos using
old sinks - but then <code>SinkMode.SEQUENTIAL</code> is to be used, causing sink to be called on each
prediction element.</p>
</div>
</td>
<td>
<code><span title="inference.core.interfaces.stream.inference_pipeline.SinkMode.ADAPTIVE">ADAPTIVE</span></code>
</td>
</tr>
</tbody>
</table>
<p>Other ENV variables involved in low-level configuration:
* INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching
* INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop
* ACTIVE_LEARNING_ENABLED - controls Active Learning middleware if explicit parameter not given</p>
<p>Returns: Instance of InferencePipeline</p>
<details class="throws" open="">
<summary>Throws</summary>
<ul>
<li>SourceConnectionError if source cannot be connected at start, however it attempts to reconnect
    always if connection to stream is lost.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>inference/core/interfaces/stream/inference_pipeline.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">init</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">]],</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">class_agnostic_nms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_candidates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_detections</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mask_decode_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"accurate"</span><span class="p">,</span>
    <span class="n">tradeoff_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">active_learning_enabled</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">active_learning_target_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sink_mode</span><span class="p">:</span> <span class="n">SinkMode</span> <span class="o">=</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This class creates the abstraction for making inferences from Roboflow models against video stream.</span>
<span class="sd">    It allows to choose model from Roboflow platform and run predictions against</span>
<span class="sd">    video streams - just by the price of specifying which model to use and what to do with predictions.</span>

<span class="sd">    It allows to set the model post-processing parameters (via .init() or env) and intercept updates</span>
<span class="sd">    related to state of pipeline via `PipelineWatchDog` abstraction (although that is something probably</span>
<span class="sd">    useful only for advanced use-cases).</span>

<span class="sd">    For maximum efficiency, all separate chunks of processing: video decoding, inference, results dispatching</span>
<span class="sd">    are handled by separate threads.</span>

<span class="sd">    Given that reference to stream is passed and connectivity is lost - it attempts to re-connect with delay.</span>

<span class="sd">    Since version 0.9.11 it works not only for object detection models but is also compatible with stubs,</span>
<span class="sd">    classification, instance-segmentation and keypoint-detection models.</span>

<span class="sd">    Since version 0.9.18, `InferencePipeline` is capable of handling multiple video sources at once. If multiple</span>
<span class="sd">    sources are provided - source multiplexing will happen. One of the change introduced in that release is switch</span>
<span class="sd">    from `get_video_frames_generator(...)` as video frames provider into `multiplex_videos(...)`. For a single</span>
<span class="sd">    video source, the behaviour of `InferencePipeline` is remained unchanged when default parameters are used.</span>
<span class="sd">    For multiple videos - frames are multiplexed, and we can adjust the pipeline behaviour using new configuration</span>
<span class="sd">    options. `batch_collection_timeout` is one of the new option - it is the parameter of `multiplex_videos(...)`</span>
<span class="sd">    that dictates how long the batch frames collection process may wait for all sources to provide video frame.</span>
<span class="sd">    It can be set infinite (None) or with specific value representing fraction of second. We advise that value to</span>
<span class="sd">    be set in production solutions to avoid processing slow-down caused by source with unstable latency spikes.</span>
<span class="sd">    For more information on multiplexing process - please visit `multiplex_videos(...)` function docs.</span>
<span class="sd">    Another change is the way on how sinks work. They can work in `SinkMode.ADAPTIVE` - which means that</span>
<span class="sd">    video frames and predictions will be either provided to sink as list of objects, or specific elements -</span>
<span class="sd">    and the determining factor is number of sources (it will behave SEQUENTIAL for one source and BATCH if multiple</span>
<span class="sd">    ones are provided). All old sinks were adjusted to work in both modes, custom ones should be migrated</span>
<span class="sd">    to reflect changes in sink function signature.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_id (str): Name and version of model on the Roboflow platform (example: "my-model/3")</span>
<span class="sd">        video_reference (Union[str, int, List[Union[str, int]]]): Reference of source or sources to be used to make</span>
<span class="sd">            predictions against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">            (we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then</span>
<span class="sd">            it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">            `sink_mode` parameter comments.</span>
<span class="sd">        on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">            once prediction is ready - passing both decoded frame, their metadata and dict with standard</span>
<span class="sd">            Roboflow model prediction (different for specific types of models).</span>
<span class="sd">        api_key (Optional[str]): Roboflow API key - if not passed - will be looked in env under "ROBOFLOW_API_KEY"</span>
<span class="sd">            and "API_KEY" variables. API key, passed in some form is required.</span>
<span class="sd">        max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">            dictate max FPS of each video source.</span>
<span class="sd">            The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">            this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">            frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">            aligned with peoples expectations.</span>
<span class="sd">            New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">            `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">            be the default one end of Q4 2024!</span>
<span class="sd">        watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">            inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">        status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">            status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">            pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">            fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">            without re-raising. Default: None.</span>
<span class="sd">        source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        class_agnostic_nms (Optional[bool]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "CLASS_AGNOSTIC_NMS" with default "False"</span>
<span class="sd">        confidence (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "CONFIDENCE" with default "0.5"</span>
<span class="sd">        iou_threshold (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "IOU_THRESHOLD" with default "0.5"</span>
<span class="sd">        max_candidates (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "MAX_CANDIDATES" with default "3000"</span>
<span class="sd">        max_detections (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "MAX_DETECTIONS" with default "300"</span>
<span class="sd">        mask_decode_mode: (Optional[str]): Parameter of model post-processing. If not given - model "accurate" is</span>
<span class="sd">            used. Applicable for instance segmentation models</span>
<span class="sd">        tradeoff_factor (Optional[float]): Parameter of model post-processing. If not 0.0 - model default is used.</span>
<span class="sd">            Applicable for instance segmentation models</span>
<span class="sd">        active_learning_enabled (Optional[bool]): Flag to enable / disable Active Learning middleware (setting it</span>
<span class="sd">            true does not guarantee any data to be collected, as data collection is controlled by Roboflow backend -</span>
<span class="sd">            it just enables middleware intercepting predictions). If not given, env variable</span>
<span class="sd">            `ACTIVE_LEARNING_ENABLED` will be used. Please point out that Active Learning will be forcefully</span>
<span class="sd">            disabled in a scenario when Roboflow API key is not given, as Roboflow account is required</span>
<span class="sd">            for this feature to be operational.</span>
<span class="sd">        video_source_properties (Optional[Union[Dict[str, float], List[Optional[Dict[str, float]]]]]):</span>
<span class="sd">            Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties</span>
<span class="sd">            cv2.CAP_PROP_*. If not given, defaults for the video source will be used.</span>
<span class="sd">            It is optional and if provided can be provided as single dict (applicable for all sources) or</span>
<span class="sd">            as list of configs. Then the list must be of length of `video_reference` and may also contain None</span>
<span class="sd">            values to denote that specific source should remain not configured.</span>
<span class="sd">            Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">        active_learning_target_dataset (Optional[str]): Parameter to be used when Active Learning data registration</span>
<span class="sd">            should happen against different dataset than the one pointed by model_id</span>
<span class="sd">        batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">            to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">            frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">            unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">        sink_mode (SinkMode): Parameter that controls how video frames and predictions will be passed to sink</span>
<span class="sd">            handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,</span>
<span class="sd">            in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned</span>
<span class="sd">            in the order of video sources - with None values in the place of vide_frames / predictions that</span>
<span class="sd">            were skipped due to `batch_collection_timeout`.</span>
<span class="sd">            `SinkMode.ADAPTIVE` is a middle ground (and default mode) - all old sources will work in that mode</span>
<span class="sd">            against a single video input, as the pipeline will behave as if running in `SinkMode.SEQUENTIAL`.</span>
<span class="sd">            To handle multiple videos - sink needs to accept `predictions: List[Optional[dict]]` and</span>
<span class="sd">            `video_frame: List[Optional[VideoFrame]]`. It is also possible to process multiple videos using</span>
<span class="sd">            old sinks - but then `SinkMode.SEQUENTIAL` is to be used, causing sink to be called on each</span>
<span class="sd">            prediction element.</span>

<span class="sd">    Other ENV variables involved in low-level configuration:</span>
<span class="sd">    * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">    * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>
<span class="sd">    * ACTIVE_LEARNING_ENABLED - controls Active Learning middleware if explicit parameter not given</span>

<span class="sd">    Returns: Instance of InferencePipeline</span>

<span class="sd">    Throws:</span>
<span class="sd">        * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">            always if connection to stream is lost.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">api_key</span> <span class="o">=</span> <span class="n">API_KEY</span>
    <span class="n">inference_config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
        <span class="n">class_agnostic_nms</span><span class="o">=</span><span class="n">class_agnostic_nms</span><span class="p">,</span>
        <span class="n">confidence</span><span class="o">=</span><span class="n">confidence</span><span class="p">,</span>
        <span class="n">iou_threshold</span><span class="o">=</span><span class="n">iou_threshold</span><span class="p">,</span>
        <span class="n">max_candidates</span><span class="o">=</span><span class="n">max_candidates</span><span class="p">,</span>
        <span class="n">max_detections</span><span class="o">=</span><span class="n">max_detections</span><span class="p">,</span>
        <span class="n">mask_decode_mode</span><span class="o">=</span><span class="n">mask_decode_mode</span><span class="p">,</span>
        <span class="n">tradeoff_factor</span><span class="o">=</span><span class="n">tradeoff_factor</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">)</span>
    <span class="n">on_video_frame</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">default_process_frame</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">inference_config</span><span class="o">=</span><span class="n">inference_config</span>
    <span class="p">)</span>
    <span class="n">active_learning_middleware</span> <span class="o">=</span> <span class="n">NullActiveLearningMiddleware</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">active_learning_enabled</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"`active_learning_enabled` parameter not set - using env `ACTIVE_LEARNING_ENABLED` "</span>
            <span class="sa">f</span><span class="s2">"with value: </span><span class="si">{</span><span class="n">ACTIVE_LEARNING_ENABLED</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span>
        <span class="n">active_learning_enabled</span> <span class="o">=</span> <span class="n">ACTIVE_LEARNING_ENABLED</span>
    <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Roboflow API key not given - Active Learning is forced to be disabled."</span>
        <span class="p">)</span>
        <span class="n">active_learning_enabled</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">active_learning_enabled</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">resolved_model_id</span> <span class="o">=</span> <span class="n">resolve_roboflow_model_alias</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
        <span class="n">target_dataset</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">active_learning_target_dataset</span> <span class="ow">or</span> <span class="n">resolved_model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">active_learning_middleware</span> <span class="o">=</span> <span class="n">ThreadingActiveLearningMiddleware</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
            <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
            <span class="n">target_dataset</span><span class="o">=</span><span class="n">target_dataset</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="n">resolved_model_id</span><span class="p">,</span>
            <span class="n">cache</span><span class="o">=</span><span class="n">cache</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">al_sink</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">active_learning_sink</span><span class="p">,</span>
            <span class="n">active_learning_middleware</span><span class="o">=</span><span class="n">active_learning_middleware</span><span class="p">,</span>
            <span class="n">model_type</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">task_type</span><span class="p">,</span>
            <span class="n">disable_preproc_auto_orient</span><span class="o">=</span><span class="n">DISABLE_PREPROC_AUTO_ORIENT</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">"AL enabled - wrapping `on_prediction` with multi_sink() and active_learning_sink()"</span>
        <span class="p">)</span>
        <span class="n">on_prediction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">multi_sink</span><span class="p">,</span> <span class="n">sinks</span><span class="o">=</span><span class="p">[</span><span class="n">on_prediction</span><span class="p">,</span> <span class="n">al_sink</span><span class="p">])</span>
    <span class="n">on_pipeline_start</span> <span class="o">=</span> <span class="n">active_learning_middleware</span><span class="o">.</span><span class="n">start_registration_thread</span>
    <span class="n">on_pipeline_end</span> <span class="o">=</span> <span class="n">active_learning_middleware</span><span class="o">.</span><span class="n">stop_registration_thread</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">init_with_custom_logic</span><span class="p">(</span>
        <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
        <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
        <span class="n">on_pipeline_start</span><span class="o">=</span><span class="n">on_pipeline_start</span><span class="p">,</span>
        <span class="n">on_pipeline_end</span><span class="o">=</span><span class="n">on_pipeline_end</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
        <span class="n">sink_mode</span><span class="o">=</span><span class="n">sink_mode</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_custom_logic">
<code class="highlight language-python"><span class="n">init_with_custom_logic</span><span class="p">(</span><span class="n">video_reference</span><span class="p">,</span> <span class="n">on_video_frame</span><span class="p">,</span> <span class="n">on_prediction</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">on_pipeline_start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">on_pipeline_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_fps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">watchdog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">status_update_handlers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">video_source_properties</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sink_mode</span><span class="o">=</span><span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">)</span></code>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
</span>
<a class="headerlink" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_custom_logic" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>This class creates the abstraction for making inferences from given workflow against video stream.
The way of how <code>InferencePipeline</code> works is displayed in <code>InferencePipeline.init(...)</code> initialiser
method.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>video_reference</code>
</td>
<td>
<code><span title="typing.Union">Union</span>[str, int, <span title="typing.List">List</span>[<span title="typing.Union">Union</span>[str, int]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Reference of source or sources to be used to make
predictions against. It can be video file path, stream URL and device (like camera) id
(we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then
it will trigger parallel processing of multiple sources. It has some implication on sinks. See:
<code>sink_mode</code> parameter comments.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>on_video_frame</code>
</td>
<td>
<code><span title="typing.Callable">Callable</span>[[<a class="autorefs autorefs-internal" title="inference.core.interfaces.camera.entities.VideoFrame" href="../../camera/entities/#inference.core.interfaces.camera.entities.VideoFrame">VideoFrame</a>], <span title="inference.core.interfaces.stream.entities.AnyPrediction">AnyPrediction</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>function supposed to make prediction (or do another
kind of custom processing according to your will). Accept <code>VideoFrame</code> object and is supposed
to return dictionary with results of any kind.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>on_prediction</code>
</td>
<td>
<code>Callable[AnyPrediction, VideoFrame], None]</code>
</td>
<td>
<div class="doc-md-description">
<p>Function to be called
once prediction is ready - passing both decoded frame, their metadata and dict with output from your
custom callable <code>on_video_frame(...)</code>. Logic here must be adjusted to the output of <code>on_video_frame</code>.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>on_pipeline_start</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[], None]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional (parameter-free) function to be called
whenever pipeline starts</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>on_pipeline_end</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[], None]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional (parameter-free) function to be called
whenever pipeline ends</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_fps</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, int]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Specific value passed as this parameter will be used to
dictate max FPS of each video source.
The implementation details of this option has been changed in release <code>v0.26.0</code>. Prior to the release
this value, when applied to video files caused the processing to wait <code>1 / max_fps</code> seconds before next
frame is processed - the new implementation drops the intermediate frames, which seems to be more
aligned with peoples expectations.
New behaviour is now enabled in experimental mode, by setting environmental variable flag
<code>ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True</code>. Please note that the new behaviour will
be the default one end of Q4 2024!</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>watchdog</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.stream.watchdog.PipelineWatchDog">PipelineWatchDog</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Implementation of class that allows profiling of
inference pipeline - if not given null implementation (doing nothing) will be used.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>status_update_handlers</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="typing.Callable">Callable</span>[[<a class="autorefs autorefs-internal" title="inference.core.interfaces.camera.entities.StatusUpdate" href="../../camera/entities/#inference.core.interfaces.camera.entities.StatusUpdate">StatusUpdate</a>], None]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of handlers to intercept
status updates of all elements of the pipeline. Should be used only if detailed inspection of
pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed
fast - otherwise they will impair pipeline performance. All errors will be logged as warnings
without re-raising. Default: None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_filling_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferFillingStrategy">BufferFillingStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream decoding behaviour. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_consumption_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferConsumptionStrategy">BufferConsumptionStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream frames consumption. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>video_source_properties</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="typing.Dict">Dict</span>[str, float], <span title="typing.List">List</span>[<span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, float]]]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties
cv2.CAP_PROP_*. If not given, defaults for the video source will be used.
It is optional and if provided can be provided as single dict (applicable for all sources) or
as list of configs. Then the list must be of length of <code>video_reference</code> and may also contain None
values to denote that specific source should remain not configured.
Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>batch_collection_timeout</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of multiplex_videos(...) dictating how long process
to grab frames from multiple sources can wait for batch to be filled before yielding already collected
frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows
unstable latency. Visit <code>multiplex_videos(...)</code> for more information about multiplexing process.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>sink_mode</code>
</td>
<td>
<code><span title="inference.core.interfaces.stream.inference_pipeline.SinkMode">SinkMode</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter that controls how video frames and predictions will be passed to sink
handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,
in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned
in the order of video sources - with None values in the place of vide_frames / predictions that
were skipped due to <code>batch_collection_timeout</code>.
<code>SinkMode.ADAPTIVE</code> is a middle ground (and default mode) - all old sources will work in that mode
against a single video input, as the pipeline will behave as if running in <code>SinkMode.SEQUENTIAL</code>.
To handle multiple videos - sink needs to accept <code>predictions: List[Optional[dict]]</code> and
<code>video_frame: List[Optional[VideoFrame]]</code>. It is also possible to process multiple videos using
old sinks - but then <code>SinkMode.SEQUENTIAL</code> is to be used, causing sink to be called on each
prediction element.</p>
</div>
</td>
<td>
<code><span title="inference.core.interfaces.stream.inference_pipeline.SinkMode.ADAPTIVE">ADAPTIVE</span></code>
</td>
</tr>
</tbody>
</table>
<p>Other ENV variables involved in low-level configuration:
* INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching
* INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</p>
<p>Returns: Instance of InferencePipeline</p>
<details class="throws" open="">
<summary>Throws</summary>
<ul>
<li>SourceConnectionError if source cannot be connected at start, however it attempts to reconnect
    always if connection to stream is lost.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>inference/core/interfaces/stream/inference_pipeline.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">init_with_custom_logic</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">VideoSourceIdentifier</span><span class="p">]],</span>
    <span class="n">on_video_frame</span><span class="p">:</span> <span class="n">InferenceHandler</span><span class="p">,</span>
    <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">on_pipeline_start</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">on_pipeline_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sink_mode</span><span class="p">:</span> <span class="n">SinkMode</span> <span class="o">=</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This class creates the abstraction for making inferences from given workflow against video stream.</span>
<span class="sd">    The way of how `InferencePipeline` works is displayed in `InferencePipeline.init(...)` initialiser</span>
<span class="sd">    method.</span>

<span class="sd">    Args:</span>
<span class="sd">        video_reference (Union[str, int, List[Union[str, int]]]): Reference of source or sources to be used to make</span>
<span class="sd">            predictions against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">            (we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then</span>
<span class="sd">            it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">            `sink_mode` parameter comments.</span>
<span class="sd">        on_video_frame (Callable[[VideoFrame], AnyPrediction]): function supposed to make prediction (or do another</span>
<span class="sd">            kind of custom processing according to your will). Accept `VideoFrame` object and is supposed</span>
<span class="sd">            to return dictionary with results of any kind.</span>
<span class="sd">        on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">            once prediction is ready - passing both decoded frame, their metadata and dict with output from your</span>
<span class="sd">            custom callable `on_video_frame(...)`. Logic here must be adjusted to the output of `on_video_frame`.</span>
<span class="sd">        on_pipeline_start (Optional[Callable[[], None]]): Optional (parameter-free) function to be called</span>
<span class="sd">            whenever pipeline starts</span>
<span class="sd">        on_pipeline_end (Optional[Callable[[], None]]): Optional (parameter-free) function to be called</span>
<span class="sd">            whenever pipeline ends</span>
<span class="sd">        max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">            dictate max FPS of each video source.</span>
<span class="sd">            The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">            this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">            frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">            aligned with peoples expectations.</span>
<span class="sd">            New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">            `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">            be the default one end of Q4 2024!</span>
<span class="sd">        watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">            inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">        status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">            status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">            pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">            fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">            without re-raising. Default: None.</span>
<span class="sd">        source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        video_source_properties (Optional[Union[Dict[str, float], List[Optional[Dict[str, float]]]]]):</span>
<span class="sd">            Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties</span>
<span class="sd">            cv2.CAP_PROP_*. If not given, defaults for the video source will be used.</span>
<span class="sd">            It is optional and if provided can be provided as single dict (applicable for all sources) or</span>
<span class="sd">            as list of configs. Then the list must be of length of `video_reference` and may also contain None</span>
<span class="sd">            values to denote that specific source should remain not configured.</span>
<span class="sd">            Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">        batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">            to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">            frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">            unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">        sink_mode (SinkMode): Parameter that controls how video frames and predictions will be passed to sink</span>
<span class="sd">            handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,</span>
<span class="sd">            in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned</span>
<span class="sd">            in the order of video sources - with None values in the place of vide_frames / predictions that</span>
<span class="sd">            were skipped due to `batch_collection_timeout`.</span>
<span class="sd">            `SinkMode.ADAPTIVE` is a middle ground (and default mode) - all old sources will work in that mode</span>
<span class="sd">            against a single video input, as the pipeline will behave as if running in `SinkMode.SEQUENTIAL`.</span>
<span class="sd">            To handle multiple videos - sink needs to accept `predictions: List[Optional[dict]]` and</span>
<span class="sd">            `video_frame: List[Optional[VideoFrame]]`. It is also possible to process multiple videos using</span>
<span class="sd">            old sinks - but then `SinkMode.SEQUENTIAL` is to be used, causing sink to be called on each</span>
<span class="sd">            prediction element.</span>

<span class="sd">    Other ENV variables involved in low-level configuration:</span>
<span class="sd">    * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">    * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>

<span class="sd">    Returns: Instance of InferencePipeline</span>

<span class="sd">    Throws:</span>
<span class="sd">        * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">            always if connection to stream is lost.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">watchdog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">watchdog</span> <span class="o">=</span> <span class="n">NullPipelineWatchdog</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">status_update_handlers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">status_update_handlers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">status_update_handlers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">watchdog</span><span class="o">.</span><span class="n">on_status_update</span><span class="p">)</span>
    <span class="n">desired_source_fps</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING</span><span class="p">:</span>
        <span class="n">desired_source_fps</span> <span class="o">=</span> <span class="n">max_fps</span>
    <span class="n">video_sources</span> <span class="o">=</span> <span class="n">prepare_video_sources</span><span class="p">(</span>
        <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
        <span class="n">desired_source_fps</span><span class="o">=</span><span class="n">desired_source_fps</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">watchdog</span><span class="o">.</span><span class="n">register_video_sources</span><span class="p">(</span><span class="n">video_sources</span><span class="o">=</span><span class="n">video_sources</span><span class="p">)</span>
    <span class="n">predictions_queue</span> <span class="o">=</span> <span class="n">Queue</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">PREDICTIONS_QUEUE_SIZE</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
        <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
        <span class="n">video_sources</span><span class="o">=</span><span class="n">video_sources</span><span class="p">,</span>
        <span class="n">predictions_queue</span><span class="o">=</span><span class="n">predictions_queue</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
        <span class="n">on_pipeline_start</span><span class="o">=</span><span class="n">on_pipeline_start</span><span class="p">,</span>
        <span class="n">on_pipeline_end</span><span class="o">=</span><span class="n">on_pipeline_end</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
        <span class="n">sink_mode</span><span class="o">=</span><span class="n">sink_mode</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_workflow">
<code class="highlight language-python"><span class="n">init_with_workflow</span><span class="p">(</span><span class="n">video_reference</span><span class="p">,</span> <span class="n">workflow_specification</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workspace_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workflow_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_input_name</span><span class="o">=</span><span class="s1">'image'</span><span class="p">,</span> <span class="n">workflows_parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">on_prediction</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_fps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">watchdog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">status_update_handlers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">video_source_properties</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workflow_init_parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">workflows_thread_pool_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">video_metadata_input_name</span><span class="o">=</span><span class="s1">'video_metadata'</span><span class="p">,</span> <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">profiling_directory</span><span class="o">=</span><span class="s1">'./inference_profiling'</span><span class="p">,</span> <span class="n">use_workflow_definition_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
</span>
<a class="headerlink" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_workflow" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>This class creates the abstraction for making inferences from given workflow against video stream.
The way of how <code>InferencePipeline</code> works is displayed in <code>InferencePipeline.init(...)</code> initializer
method.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>video_reference</code>
</td>
<td>
<code><span title="typing.Union">Union</span>[str, int, <span title="typing.List">List</span>[<span title="typing.Union">Union</span>[str, int]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Reference of source to be used to make predictions
against. It can be video file path, stream URL and device (like camera) id
(we handle whatever cv2 handles). It can also be a list of references (since v0.13.0) - and then
it will trigger parallel processing of multiple sources. It has some implication on sinks. See:
<code>sink_mode</code> parameter comments.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>workflow_specification</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[dict]</code>
</td>
<td>
<div class="doc-md-description">
<p>Valid specification of workflow. See <a href="https://github.com/roboflow/inference/tree/main/inference/enterprise/workflows">workflow docs</a>.
It can be provided optionally, but if not given, both <code>workspace_name</code> and <code>workflow_id</code>
must be provided.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>workspace_name</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>When using registered workflows - Roboflow workspace name needs to be given.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>workflow_id</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>When using registered workflows - Roboflow workflow id needs to be given.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>api_key</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>Roboflow API key - if not passed - will be looked in env under "ROBOFLOW_API_KEY"
and "API_KEY" variables. API key, passed in some form is required.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>image_input_name</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>Name of input image defined in <code>workflow_specification</code> or Workflow definition saved
on the Roboflow Platform. <code>InferencePipeline</code> will be injecting video frames to workflow through that
parameter name.</p>
</div>
</td>
<td>
<code>'image'</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>workflows_parameters</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Dictionary with additional parameters that can be
defined within <code>workflow_specification</code>.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>on_prediction</code>
</td>
<td>
<code>Callable[AnyPrediction, VideoFrame], None]</code>
</td>
<td>
<div class="doc-md-description">
<p>Function to be called
once prediction is ready - passing both decoded frame, their metadata and dict with workflow output.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_fps</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, int]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Specific value passed as this parameter will be used to
dictate max FPS of each video source.
The implementation details of this option has been changed in release <code>v0.26.0</code>. Prior to the release
this value, when applied to video files caused the processing to wait <code>1 / max_fps</code> seconds before next
frame is processed - the new implementation drops the intermediate frames, which seems to be more
aligned with peoples expectations.
New behaviour is now enabled in experimental mode, by setting environmental variable flag
<code>ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True</code>. Please note that the new behaviour will
be the default one end of Q4 2024!</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>watchdog</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.stream.watchdog.PipelineWatchDog">PipelineWatchDog</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Implementation of class that allows profiling of
inference pipeline - if not given null implementation (doing nothing) will be used.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>status_update_handlers</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="typing.Callable">Callable</span>[[<a class="autorefs autorefs-internal" title="inference.core.interfaces.camera.entities.StatusUpdate" href="../../camera/entities/#inference.core.interfaces.camera.entities.StatusUpdate">StatusUpdate</a>], None]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of handlers to intercept
status updates of all elements of the pipeline. Should be used only if detailed inspection of
pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed
fast - otherwise they will impair pipeline performance. All errors will be logged as warnings
without re-raising. Default: None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_filling_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferFillingStrategy">BufferFillingStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream decoding behaviour. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_consumption_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferConsumptionStrategy">BufferConsumptionStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream frames consumption. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>video_source_properties</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[dict[str, float]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional source properties to set up the video source,
corresponding to cv2 VideoCapture properties cv2.CAP_PROP_*. If not given, defaults for the video source
will be used.
Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>workflow_init_parameters</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Additional init parameters to be used by
workflows Execution Engine to init steps of your workflow - may be required when running workflows
with custom plugins.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>workflows_thread_pool_workers</code>
</td>
<td>
<code>int</code>
</td>
<td>
<div class="doc-md-description">
<p>Number of workers for workflows thread pool which is used
by workflows blocks to run background tasks.</p>
</div>
</td>
<td>
<code>4</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>cancel_thread_pool_tasks_on_exit</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Flag to decide if unstated background tasks should be
canceled at the end of InferencePipeline processing. By default, when video file ends or
pipeline is stopped, tasks that has not started will be cancelled.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>video_metadata_input_name</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>Name of input for video metadata defined in <code>workflow_specification</code> or
Workflow definition saved  on the Roboflow Platform. <code>InferencePipeline</code> will be injecting video frames
metadata to workflows through that parameter name.</p>
</div>
</td>
<td>
<code>'video_metadata'</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>batch_collection_timeout</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of multiplex_videos(...) dictating how long process
to grab frames from multiple sources can wait for batch to be filled before yielding already collected
frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows
unstable latency. Visit <code>multiplex_videos(...)</code> for more information about multiplexing process.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>profiling_directory</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>Directory where workflows profiler traces will be dumped. To enable profiling
export <code>ENABLE_WORKFLOWS_PROFILING=True</code> environmental variable. You may specify number of workflow
runs in a buffer with environmental variable <code>WORKFLOWS_PROFILER_BUFFER_SIZE=n</code> - making last <code>n</code>
frames to be present in buffer on processing end.</p>
</div>
</td>
<td>
<code>'./inference_profiling'</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>use_workflow_definition_cache</code>
</td>
<td>
<code>bool</code>
</td>
<td>
<div class="doc-md-description">
<p>Controls usage of cache for workflow definitions. Set this to False
when you frequently modify definition saved in Roboflow app and want to fetch the
newest version for the request. Only applies for Workflows definitions saved on Roboflow platform.</p>
</div>
</td>
<td>
<code>True</code>
</td>
</tr>
</tbody>
</table>
<p>Other ENV variables involved in low-level configuration:
* INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching
* INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</p>
<p>Returns: Instance of InferencePipeline</p>
<details class="throws" open="">
<summary>Throws</summary>
<ul>
<li>SourceConnectionError if source cannot be connected at start, however it attempts to reconnect
    always if connection to stream is lost.</li>
<li>ValueError if workflow specification not provided and registered workflow not pointed out</li>
<li>NotImplementedError if workflow used against multiple videos which is not supported yet</li>
<li>MissingApiKeyError - if API key is not provided in situation when retrieving workflow definition
    from Roboflow API is needed</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>inference/core/interfaces/stream/inference_pipeline.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="nd">@experimental</span><span class="p">(</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">"Usage of workflows with `InferencePipeline` is an experimental feature. Please report any issues "</span>
    <span class="s2">"here: https://github.com/roboflow/inference/issues"</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">init_with_workflow</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
    <span class="n">workflow_specification</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workspace_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workflow_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">api_key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"image"</span><span class="p">,</span>
    <span class="n">workflows_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workflow_init_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">workflows_thread_pool_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">video_metadata_input_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"video_metadata"</span><span class="p">,</span>
    <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">profiling_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"./inference_profiling"</span><span class="p">,</span>
    <span class="n">use_workflow_definition_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This class creates the abstraction for making inferences from given workflow against video stream.</span>
<span class="sd">    The way of how `InferencePipeline` works is displayed in `InferencePipeline.init(...)` initializer</span>
<span class="sd">    method.</span>

<span class="sd">    Args:</span>
<span class="sd">        video_reference (Union[str, int, List[Union[str, int]]]): Reference of source to be used to make predictions</span>
<span class="sd">            against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">            (we handle whatever cv2 handles). It can also be a list of references (since v0.13.0) - and then</span>
<span class="sd">            it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">            `sink_mode` parameter comments.</span>
<span class="sd">        workflow_specification (Optional[dict]): Valid specification of workflow. See [workflow docs](https://github.com/roboflow/inference/tree/main/inference/enterprise/workflows).</span>
<span class="sd">            It can be provided optionally, but if not given, both `workspace_name` and `workflow_id`</span>
<span class="sd">            must be provided.</span>
<span class="sd">        workspace_name (Optional[str]): When using registered workflows - Roboflow workspace name needs to be given.</span>
<span class="sd">        workflow_id (Optional[str]): When using registered workflows - Roboflow workflow id needs to be given.</span>
<span class="sd">        api_key (Optional[str]): Roboflow API key - if not passed - will be looked in env under "ROBOFLOW_API_KEY"</span>
<span class="sd">            and "API_KEY" variables. API key, passed in some form is required.</span>
<span class="sd">        image_input_name (str): Name of input image defined in `workflow_specification` or Workflow definition saved</span>
<span class="sd">            on the Roboflow Platform. `InferencePipeline` will be injecting video frames to workflow through that</span>
<span class="sd">            parameter name.</span>
<span class="sd">        workflows_parameters (Optional[Dict[str, Any]]): Dictionary with additional parameters that can be</span>
<span class="sd">            defined within `workflow_specification`.</span>
<span class="sd">        on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">            once prediction is ready - passing both decoded frame, their metadata and dict with workflow output.</span>
<span class="sd">        max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">            dictate max FPS of each video source.</span>
<span class="sd">            The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">            this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">            frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">            aligned with peoples expectations.</span>
<span class="sd">            New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">            `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">            be the default one end of Q4 2024!</span>
<span class="sd">        watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">            inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">        status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">            status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">            pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">            fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">            without re-raising. Default: None.</span>
<span class="sd">        source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        video_source_properties (Optional[dict[str, float]]): Optional source properties to set up the video source,</span>
<span class="sd">            corresponding to cv2 VideoCapture properties cv2.CAP_PROP_*. If not given, defaults for the video source</span>
<span class="sd">            will be used.</span>
<span class="sd">            Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">        workflow_init_parameters (Optional[Dict[str, Any]]): Additional init parameters to be used by</span>
<span class="sd">            workflows Execution Engine to init steps of your workflow - may be required when running workflows</span>
<span class="sd">            with custom plugins.</span>
<span class="sd">        workflows_thread_pool_workers (int): Number of workers for workflows thread pool which is used</span>
<span class="sd">            by workflows blocks to run background tasks.</span>
<span class="sd">        cancel_thread_pool_tasks_on_exit (bool): Flag to decide if unstated background tasks should be</span>
<span class="sd">            canceled at the end of InferencePipeline processing. By default, when video file ends or</span>
<span class="sd">            pipeline is stopped, tasks that has not started will be cancelled.</span>
<span class="sd">        video_metadata_input_name (str): Name of input for video metadata defined in `workflow_specification` or</span>
<span class="sd">            Workflow definition saved  on the Roboflow Platform. `InferencePipeline` will be injecting video frames</span>
<span class="sd">            metadata to workflows through that parameter name.</span>
<span class="sd">        batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">            to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">            frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">            unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">        profiling_directory (str): Directory where workflows profiler traces will be dumped. To enable profiling</span>
<span class="sd">            export `ENABLE_WORKFLOWS_PROFILING=True` environmental variable. You may specify number of workflow</span>
<span class="sd">            runs in a buffer with environmental variable `WORKFLOWS_PROFILER_BUFFER_SIZE=n` - making last `n`</span>
<span class="sd">            frames to be present in buffer on processing end.</span>
<span class="sd">        use_workflow_definition_cache (bool): Controls usage of cache for workflow definitions. Set this to False</span>
<span class="sd">            when you frequently modify definition saved in Roboflow app and want to fetch the</span>
<span class="sd">            newest version for the request. Only applies for Workflows definitions saved on Roboflow platform.</span>

<span class="sd">    Other ENV variables involved in low-level configuration:</span>
<span class="sd">    * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">    * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>

<span class="sd">    Returns: Instance of InferencePipeline</span>

<span class="sd">    Throws:</span>
<span class="sd">        * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">            always if connection to stream is lost.</span>
<span class="sd">        * ValueError if workflow specification not provided and registered workflow not pointed out</span>
<span class="sd">        * NotImplementedError if workflow used against multiple videos which is not supported yet</span>
<span class="sd">        * MissingApiKeyError - if API key is not provided in situation when retrieving workflow definition</span>
<span class="sd">            from Roboflow API is needed</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">ENABLE_WORKFLOWS_PROFILING</span><span class="p">:</span>
        <span class="n">profiler</span> <span class="o">=</span> <span class="n">BaseWorkflowsProfiler</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
            <span class="n">max_runs_in_buffer</span><span class="o">=</span><span class="n">WORKFLOWS_PROFILER_BUFFER_SIZE</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">profiler</span> <span class="o">=</span> <span class="n">NullWorkflowsProfiler</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">api_key</span> <span class="o">=</span> <span class="n">API_KEY</span>
    <span class="n">named_workflow_specified</span> <span class="o">=</span> <span class="p">(</span><span class="n">workspace_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="n">workflow_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">named_workflow_specified</span> <span class="o">!=</span> <span class="p">(</span><span class="n">workflow_specification</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">"Parameters (`workspace_name`, `workflow_id`) can be used mutually exclusive with "</span>
            <span class="s2">"`workflow_specification`, but at least one must be set."</span>
        <span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">inference.core.interfaces.stream.model_handlers.workflows</span> <span class="kn">import</span> <span class="p">(</span>
            <span class="n">WorkflowRunner</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="kn">from</span> <span class="nn">inference.core.roboflow_api</span> <span class="kn">import</span> <span class="n">get_workflow_specification</span>
        <span class="kn">from</span> <span class="nn">inference.core.workflows.execution_engine.core</span> <span class="kn">import</span> <span class="n">ExecutionEngine</span>

        <span class="k">if</span> <span class="n">workflow_specification</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MissingApiKeyError</span><span class="p">(</span>
                    <span class="s2">"Roboflow API key needs to be provided either as parameter or via env variable "</span>
                    <span class="s2">"ROBOFLOW_API_KEY. If you do not know how to get API key - visit "</span>
                    <span class="s2">"https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key to learn how to "</span>
                    <span class="s2">"retrieve one."</span>
                <span class="p">)</span>
            <span class="k">with</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile_execution_phase</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">"workflow_definition_fetching"</span><span class="p">,</span>
                <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="s2">"inference_package_operation"</span><span class="p">],</span>
            <span class="p">):</span>
                <span class="n">workflow_specification</span> <span class="o">=</span> <span class="n">get_workflow_specification</span><span class="p">(</span>
                    <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
                    <span class="n">workspace_id</span><span class="o">=</span><span class="n">workspace_name</span><span class="p">,</span>
                    <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_id</span><span class="p">,</span>
                    <span class="n">use_cache</span><span class="o">=</span><span class="n">use_workflow_definition_cache</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="n">model_registry</span> <span class="o">=</span> <span class="n">RoboflowModelRegistry</span><span class="p">(</span><span class="n">ROBOFLOW_MODEL_TYPES</span><span class="p">)</span>
        <span class="n">model_manager</span> <span class="o">=</span> <span class="n">BackgroundTaskActiveLearningManager</span><span class="p">(</span>
            <span class="n">model_registry</span><span class="o">=</span><span class="n">model_registry</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="n">cache</span>
        <span class="p">)</span>
        <span class="n">model_manager</span> <span class="o">=</span> <span class="n">WithFixedSizeCache</span><span class="p">(</span>
            <span class="n">model_manager</span><span class="p">,</span>
            <span class="n">max_size</span><span class="o">=</span><span class="n">MAX_ACTIVE_MODELS</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">api_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">api_key</span> <span class="o">=</span> <span class="n">API_KEY</span>
        <span class="k">if</span> <span class="n">workflow_init_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">workflow_init_parameters</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">thread_pool_executor</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span>
            <span class="n">max_workers</span><span class="o">=</span><span class="n">workflows_thread_pool_workers</span>
        <span class="p">)</span>
        <span class="n">workflow_init_parameters</span><span class="p">[</span><span class="s2">"workflows_core.model_manager"</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_manager</span>
        <span class="n">workflow_init_parameters</span><span class="p">[</span><span class="s2">"workflows_core.api_key"</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_key</span>
        <span class="n">workflow_init_parameters</span><span class="p">[</span><span class="s2">"workflows_core.thread_pool_executor"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">thread_pool_executor</span>
        <span class="p">)</span>
        <span class="n">execution_engine</span> <span class="o">=</span> <span class="n">ExecutionEngine</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
            <span class="n">workflow_definition</span><span class="o">=</span><span class="n">workflow_specification</span><span class="p">,</span>
            <span class="n">init_parameters</span><span class="o">=</span><span class="n">workflow_init_parameters</span><span class="p">,</span>
            <span class="n">workflow_id</span><span class="o">=</span><span class="n">workflow_id</span><span class="p">,</span>
            <span class="n">profiler</span><span class="o">=</span><span class="n">profiler</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">workflow_runner</span> <span class="o">=</span> <span class="n">WorkflowRunner</span><span class="p">()</span>
        <span class="n">on_video_frame</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">workflow_runner</span><span class="o">.</span><span class="n">run_workflow</span><span class="p">,</span>
            <span class="n">workflows_parameters</span><span class="o">=</span><span class="n">workflows_parameters</span><span class="p">,</span>
            <span class="n">execution_engine</span><span class="o">=</span><span class="n">execution_engine</span><span class="p">,</span>
            <span class="n">image_input_name</span><span class="o">=</span><span class="n">image_input_name</span><span class="p">,</span>
            <span class="n">video_metadata_input_name</span><span class="o">=</span><span class="n">video_metadata_input_name</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">CannotInitialiseModelError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Could not initialise workflow processing due to lack of dependencies required. "</span>
            <span class="sa">f</span><span class="s2">"Please provide an issue report under https://github.com/roboflow/inference/issues"</span>
        <span class="p">)</span> <span class="kn">from</span> <span class="nn">error</span>
    <span class="n">on_pipeline_end_closure</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
        <span class="n">on_pipeline_end</span><span class="p">,</span>
        <span class="n">thread_pool_executor</span><span class="o">=</span><span class="n">thread_pool_executor</span><span class="p">,</span>
        <span class="n">cancel_thread_pool_tasks_on_exit</span><span class="o">=</span><span class="n">cancel_thread_pool_tasks_on_exit</span><span class="p">,</span>
        <span class="n">profiler</span><span class="o">=</span><span class="n">profiler</span><span class="p">,</span>
        <span class="n">profiling_directory</span><span class="o">=</span><span class="n">profiling_directory</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">init_with_custom_logic</span><span class="p">(</span>
        <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
        <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
        <span class="n">on_pipeline_start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">on_pipeline_end</span><span class="o">=</span><span class="n">on_pipeline_end_closure</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_yolo_world">
<code class="highlight language-python"><span class="n">init_with_yolo_world</span><span class="p">(</span><span class="n">video_reference</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">model_size</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">on_prediction</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_fps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">watchdog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">status_update_handlers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_agnostic_nms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">iou_threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_candidates</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_detections</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">video_source_properties</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sink_mode</span><span class="o">=</span><span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">)</span></code>
<span class="doc doc-labels">
<small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
</span>
<a class="headerlink" href="#inference.core.interfaces.stream.inference_pipeline.InferencePipeline.init_with_yolo_world" title="Permanent link">¶</a></h3>
<div class="doc doc-contents">
<p>This class creates the abstraction for making inferences from YoloWorld against video stream.
The way of how <code>InferencePipeline</code> works is displayed in <code>InferencePipeline.init(...)</code> initializer
method.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>video_reference</code>
</td>
<td>
<code><span title="typing.Union">Union</span>[str, int, <span title="typing.List">List</span>[<span title="typing.Union">Union</span>[str, int]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Reference of source or sources to be used to make
predictions against. It can be video file path, stream URL and device (like camera) id
(we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then
it will trigger parallel processing of multiple sources. It has some implication on sinks. See:
<code>sink_mode</code> parameter comments.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>classes</code>
</td>
<td>
<code><span title="typing.List">List</span>[str]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of classes to execute zero-shot detection against</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>model_size</code>
</td>
<td>
<code>str</code>
</td>
<td>
<div class="doc-md-description">
<p>version of model - to be chosen from <code>s</code>, <code>m</code>, <code>l</code></p>
</div>
</td>
<td>
<code>'s'</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>on_prediction</code>
</td>
<td>
<code>Callable[AnyPrediction, VideoFrame], None]</code>
</td>
<td>
<div class="doc-md-description">
<p>Function to be called
once prediction is ready - passing both decoded frame, their metadata and dict with standard
Roboflow Object Detection prediction.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_fps</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, int]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Specific value passed as this parameter will be used to
dictate max FPS of each video source.
The implementation details of this option has been changed in release <code>v0.26.0</code>. Prior to the release
this value, when applied to video files caused the processing to wait <code>1 / max_fps</code> seconds before next
frame is processed - the new implementation drops the intermediate frames, which seems to be more
aligned with peoples expectations.
New behaviour is now enabled in experimental mode, by setting environmental variable flag
<code>ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True</code>. Please note that the new behaviour will
be the default one end of Q4 2024!</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>watchdog</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.stream.watchdog.PipelineWatchDog">PipelineWatchDog</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Implementation of class that allows profiling of
inference pipeline - if not given null implementation (doing nothing) will be used.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>status_update_handlers</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="typing.Callable">Callable</span>[[<a class="autorefs autorefs-internal" title="inference.core.interfaces.camera.entities.StatusUpdate" href="../../camera/entities/#inference.core.interfaces.camera.entities.StatusUpdate">StatusUpdate</a>], None]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>List of handlers to intercept
status updates of all elements of the pipeline. Should be used only if detailed inspection of
pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed
fast - otherwise they will impair pipeline performance. All errors will be logged as warnings
without re-raising. Default: None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_filling_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferFillingStrategy">BufferFillingStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream decoding behaviour. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>source_buffer_consumption_strategy</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="inference.core.interfaces.camera.video_source.BufferConsumptionStrategy">BufferConsumptionStrategy</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter dictating strategy for
video stream frames consumption. By default - tweaked to the type of source given.
Please find detailed explanation in docs of <a href="/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource"><code>VideoSource</code></a></p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>class_agnostic_nms</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[bool]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "CLASS_AGNOSTIC_NMS" with default "False"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>confidence</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "CONFIDENCE" with default "0.5"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>iou_threshold</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "IOU_THRESHOLD" with default "0.5"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_candidates</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[int]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "MAX_CANDIDATES" with default "3000"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_detections</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[int]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of model post-processing. If not given - value checked in
env variable "MAX_DETECTIONS" with default "300"</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>video_source_properties</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="typing.Dict">Dict</span>[str, float], <span title="typing.List">List</span>[<span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, float]]]]]</code>
</td>
<td>
<div class="doc-md-description">
<p>Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties
cv2.CAP_PROP_*. If not given, defaults for the video source will be used.
It is optional and if provided can be provided as single dict (applicable for all sources) or
as list of configs. Then the list must be of length of <code>video_reference</code> and may also contain None
values to denote that specific source should remain not configured.
Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>batch_collection_timeout</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[float]</code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter of multiplex_videos(...) dictating how long process
to grab frames from multiple sources can wait for batch to be filled before yielding already collected
frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows
unstable latency. Visit <code>multiplex_videos(...)</code> for more information about multiplexing process.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>sink_mode</code>
</td>
<td>
<code><span title="inference.core.interfaces.stream.inference_pipeline.SinkMode">SinkMode</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Parameter that controls how video frames and predictions will be passed to sink
handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,
in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned
in the order of video sources - with None values in the place of vide_frames / predictions that
were skipped due to <code>batch_collection_timeout</code>.
<code>SinkMode.ADAPTIVE</code> is a middle ground (and default mode) - all old sources will work in that mode
against a single video input, as the pipeline will behave as if running in <code>SinkMode.SEQUENTIAL</code>.
To handle multiple videos - sink needs to accept <code>predictions: List[Optional[dict]]</code> and
<code>video_frame: List[Optional[VideoFrame]]</code>. It is also possible to process multiple videos using
old sinks - but then <code>SinkMode.SEQUENTIAL</code> is to be used, causing sink to be called on each
prediction element.</p>
</div>
</td>
<td>
<code><span title="inference.core.interfaces.stream.inference_pipeline.SinkMode.ADAPTIVE">ADAPTIVE</span></code>
</td>
</tr>
</tbody>
</table>
<p>Other ENV variables involved in low-level configuration:
* INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching
* INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</p>
<p>Returns: Instance of InferencePipeline</p>
<details class="throws" open="">
<summary>Throws</summary>
<ul>
<li>SourceConnectionError if source cannot be connected at start, however it attempts to reconnect
    always if connection to stream is lost.</li>
</ul>
</details>
<details class="quote">
<summary>Source code in <code>inference/core/interfaces/stream/inference_pipeline.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">init_with_yolo_world</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">video_reference</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
    <span class="n">classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">model_size</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"s"</span><span class="p">,</span>
    <span class="n">on_prediction</span><span class="p">:</span> <span class="n">SinkHandler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_fps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">watchdog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineWatchDog</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">status_update_handlers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">StatusUpdate</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_filling_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferFillingStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">source_buffer_consumption_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BufferConsumptionStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">class_agnostic_nms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">iou_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_candidates</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_detections</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">video_source_properties</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_collection_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sink_mode</span><span class="p">:</span> <span class="n">SinkMode</span> <span class="o">=</span> <span class="n">SinkMode</span><span class="o">.</span><span class="n">ADAPTIVE</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">"InferencePipeline"</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This class creates the abstraction for making inferences from YoloWorld against video stream.</span>
<span class="sd">    The way of how `InferencePipeline` works is displayed in `InferencePipeline.init(...)` initializer</span>
<span class="sd">    method.</span>

<span class="sd">    Args:</span>
<span class="sd">        video_reference (Union[str, int, List[Union[str, int]]]): Reference of source or sources to be used to make</span>
<span class="sd">            predictions against. It can be video file path, stream URL and device (like camera) id</span>
<span class="sd">            (we handle whatever cv2 handles). It can also be a list of references (since v0.9.18) - and then</span>
<span class="sd">            it will trigger parallel processing of multiple sources. It has some implication on sinks. See:</span>
<span class="sd">            `sink_mode` parameter comments.</span>
<span class="sd">        classes (List[str]): List of classes to execute zero-shot detection against</span>
<span class="sd">        model_size (str): version of model - to be chosen from `s`, `m`, `l`</span>
<span class="sd">        on_prediction (Callable[AnyPrediction, VideoFrame], None]): Function to be called</span>
<span class="sd">            once prediction is ready - passing both decoded frame, their metadata and dict with standard</span>
<span class="sd">            Roboflow Object Detection prediction.</span>
<span class="sd">        max_fps (Optional[Union[float, int]]): Specific value passed as this parameter will be used to</span>
<span class="sd">            dictate max FPS of each video source.</span>
<span class="sd">            The implementation details of this option has been changed in release `v0.26.0`. Prior to the release</span>
<span class="sd">            this value, when applied to video files caused the processing to wait `1 / max_fps` seconds before next</span>
<span class="sd">            frame is processed - the new implementation drops the intermediate frames, which seems to be more</span>
<span class="sd">            aligned with peoples expectations.</span>
<span class="sd">            New behaviour is now enabled in experimental mode, by setting environmental variable flag</span>
<span class="sd">            `ENABLE_FRAME_DROP_ON_VIDEO_FILE_RATE_LIMITING=True`. Please note that the new behaviour will</span>
<span class="sd">            be the default one end of Q4 2024!</span>
<span class="sd">        watchdog (Optional[PipelineWatchDog]): Implementation of class that allows profiling of</span>
<span class="sd">            inference pipeline - if not given null implementation (doing nothing) will be used.</span>
<span class="sd">        status_update_handlers (Optional[List[Callable[[StatusUpdate], None]]]): List of handlers to intercept</span>
<span class="sd">            status updates of all elements of the pipeline. Should be used only if detailed inspection of</span>
<span class="sd">            pipeline behaviour in time is needed. Please point out that handlers should be possible to be executed</span>
<span class="sd">            fast - otherwise they will impair pipeline performance. All errors will be logged as warnings</span>
<span class="sd">            without re-raising. Default: None.</span>
<span class="sd">        source_buffer_filling_strategy (Optional[BufferFillingStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream decoding behaviour. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        source_buffer_consumption_strategy (Optional[BufferConsumptionStrategy]): Parameter dictating strategy for</span>
<span class="sd">            video stream frames consumption. By default - tweaked to the type of source given.</span>
<span class="sd">            Please find detailed explanation in docs of [`VideoSource`](/docs/reference/inference/core/interfaces/camera/video_source/#inference.core.interfaces.camera.video_source.VideoSource)</span>
<span class="sd">        class_agnostic_nms (Optional[bool]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "CLASS_AGNOSTIC_NMS" with default "False"</span>
<span class="sd">        confidence (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "CONFIDENCE" with default "0.5"</span>
<span class="sd">        iou_threshold (Optional[float]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "IOU_THRESHOLD" with default "0.5"</span>
<span class="sd">        max_candidates (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "MAX_CANDIDATES" with default "3000"</span>
<span class="sd">        max_detections (Optional[int]): Parameter of model post-processing. If not given - value checked in</span>
<span class="sd">            env variable "MAX_DETECTIONS" with default "300"</span>
<span class="sd">        video_source_properties (Optional[Union[Dict[str, float], List[Optional[Dict[str, float]]]]]):</span>
<span class="sd">            Optional source properties to set up the video source, corresponding to cv2 VideoCapture properties</span>
<span class="sd">            cv2.CAP_PROP_*. If not given, defaults for the video source will be used.</span>
<span class="sd">            It is optional and if provided can be provided as single dict (applicable for all sources) or</span>
<span class="sd">            as list of configs. Then the list must be of length of `video_reference` and may also contain None</span>
<span class="sd">            values to denote that specific source should remain not configured.</span>
<span class="sd">            Example valid properties are: {"frame_width": 1920, "frame_height": 1080, "fps": 30.0}</span>
<span class="sd">        batch_collection_timeout (Optional[float]): Parameter of multiplex_videos(...) dictating how long process</span>
<span class="sd">            to grab frames from multiple sources can wait for batch to be filled before yielding already collected</span>
<span class="sd">            frames. Please set this value in PRODUCTION to avoid performance drops when specific sources shows</span>
<span class="sd">            unstable latency. Visit `multiplex_videos(...)` for more information about multiplexing process.</span>
<span class="sd">        sink_mode (SinkMode): Parameter that controls how video frames and predictions will be passed to sink</span>
<span class="sd">            handler. With SinkMode.SEQUENTIAL - each frame and prediction triggers separate call for sink,</span>
<span class="sd">            in case of SinkMode.BATCH - list of frames and predictions will be provided to sink, always aligned</span>
<span class="sd">            in the order of video sources - with None values in the place of vide_frames / predictions that</span>
<span class="sd">            were skipped due to `batch_collection_timeout`.</span>
<span class="sd">            `SinkMode.ADAPTIVE` is a middle ground (and default mode) - all old sources will work in that mode</span>
<span class="sd">            against a single video input, as the pipeline will behave as if running in `SinkMode.SEQUENTIAL`.</span>
<span class="sd">            To handle multiple videos - sink needs to accept `predictions: List[Optional[dict]]` and</span>
<span class="sd">            `video_frame: List[Optional[VideoFrame]]`. It is also possible to process multiple videos using</span>
<span class="sd">            old sinks - but then `SinkMode.SEQUENTIAL` is to be used, causing sink to be called on each</span>
<span class="sd">            prediction element.</span>

<span class="sd">    Other ENV variables involved in low-level configuration:</span>
<span class="sd">    * INFERENCE_PIPELINE_PREDICTIONS_QUEUE_SIZE - size of buffer for predictions that are ready for dispatching</span>
<span class="sd">    * INFERENCE_PIPELINE_RESTART_ATTEMPT_DELAY - delay for restarts on stream connection drop</span>

<span class="sd">    Returns: Instance of InferencePipeline</span>

<span class="sd">    Throws:</span>
<span class="sd">        * SourceConnectionError if source cannot be connected at start, however it attempts to reconnect</span>
<span class="sd">            always if connection to stream is lost.</span>
<span class="sd">    """</span>
    <span class="n">inference_config</span> <span class="o">=</span> <span class="n">ModelConfig</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
        <span class="n">class_agnostic_nms</span><span class="o">=</span><span class="n">class_agnostic_nms</span><span class="p">,</span>
        <span class="n">confidence</span><span class="o">=</span><span class="n">confidence</span><span class="p">,</span>
        <span class="n">iou_threshold</span><span class="o">=</span><span class="n">iou_threshold</span><span class="p">,</span>
        <span class="n">max_candidates</span><span class="o">=</span><span class="n">max_candidates</span><span class="p">,</span>
        <span class="n">max_detections</span><span class="o">=</span><span class="n">max_detections</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">inference.core.interfaces.stream.model_handlers.yolo_world</span> <span class="kn">import</span> <span class="p">(</span>
            <span class="n">build_yolo_world_inference_function</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">on_video_frame</span> <span class="o">=</span> <span class="n">build_yolo_world_inference_function</span><span class="p">(</span>
            <span class="n">model_id</span><span class="o">=</span><span class="sa">f</span><span class="s2">"yolo_world/</span><span class="si">{</span><span class="n">model_size</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
            <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
            <span class="n">inference_config</span><span class="o">=</span><span class="n">inference_config</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">CannotInitialiseModelError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Could not initialise yolo_world/</span><span class="si">{</span><span class="n">model_size</span><span class="si">}</span><span class="s2"> due to lack of sufficient dependencies. "</span>
            <span class="sa">f</span><span class="s2">"Use pip install inference[yolo-world] to install missing dependencies and try again."</span>
        <span class="p">)</span> <span class="kn">from</span> <span class="nn">error</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">init_with_custom_logic</span><span class="p">(</span>
        <span class="n">video_reference</span><span class="o">=</span><span class="n">video_reference</span><span class="p">,</span>
        <span class="n">on_video_frame</span><span class="o">=</span><span class="n">on_video_frame</span><span class="p">,</span>
        <span class="n">on_prediction</span><span class="o">=</span><span class="n">on_prediction</span><span class="p">,</span>
        <span class="n">on_pipeline_start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">on_pipeline_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_fps</span><span class="o">=</span><span class="n">max_fps</span><span class="p">,</span>
        <span class="n">watchdog</span><span class="o">=</span><span class="n">watchdog</span><span class="p">,</span>
        <span class="n">status_update_handlers</span><span class="o">=</span><span class="n">status_update_handlers</span><span class="p">,</span>
        <span class="n">source_buffer_filling_strategy</span><span class="o">=</span><span class="n">source_buffer_filling_strategy</span><span class="p">,</span>
        <span class="n">source_buffer_consumption_strategy</span><span class="o">=</span><span class="n">source_buffer_consumption_strategy</span><span class="p">,</span>
        <span class="n">video_source_properties</span><span class="o">=</span><span class="n">video_source_properties</span><span class="p">,</span>
        <span class="n">batch_collection_timeout</span><span class="o">=</span><span class="n">batch_collection_timeout</span><span class="p">,</span>
        <span class="n">sink_mode</span><span class="o">=</span><span class="n">sink_mode</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: entities" class="md-footer__link md-footer__link--prev" href="../entities/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                entities
              </div>
</div>
</a>
<a aria-label="Next: roboflow_models" class="md-footer__link md-footer__link--next" href="../model_handlers/roboflow_models/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                roboflow_models
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Roboflow 2024. All rights reserved.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/roboflow" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
<a class="md-social__link" href="https://www.youtube.com/roboflow" rel="noopener" target="_blank" title="www.youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/roboflow-ai/mycompany/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg>
</a>
<a class="md-social__link" href="https://twitter.com/roboflow" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../../../../../..", "features": ["navigation.top", "navigation.tabs", "navigation.tabs.sticky", "navigation.prune", "navigation.footer", "navigation.tracking", "navigation.indexes", "navigation.sections", "content.code.copy"], "search": "../../../../../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": 1.0}}</script>
<script src="../../../../../../../assets/javascripts/bundle.3220b9d7.min.js"></script>
<script src="https://widget.kapa.ai/kapa-widget.bundle.js"></script>
<script src="../../../../../../../javascript/init_kapa_widget.js"></script>
<script src="../../../../../../../javascript/cookbooks.js"></script>
<script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body>
</html>